# pseudonymization/__init__.py - κ°•ν™”λ λ³µμ› ν•¨μ ν¬ν•¨ λ²„μ „
"""
GenAI Pseudonymizer (AenganZ Enhanced) - κ°•ν™”λ μ—­λ³µνΈν™” λ²„μ „

μ£Όμ” κΈ°λ¥:
- κ°•ν™”λ μ΅°μ‚¬ μ²λ¦¬ (λ‹, μ”¨, μ΄, κ°€, μ„, λ¥Ό λ“±)
- 1:1 λ§¤ν•‘ μ „λµμΌλ΅ μ •ν™•ν• λ³µμ›
- μ΅΄μΉ­ λ³΄μ΅΄ μ²λ¦¬
- μ‹¤μ  κ°€λ… μΉν™ (κΉ€κ°€λ…, μ΄κ°€λ… λ“±)
- μ¤λ§νΈ μ£Όμ† μ²λ¦¬ (κ°λ³„ λ§¤ν•‘)
- μΌλ°λ…μ‚¬ ν•„ν„°λ§ (κ³ κ°, μ†λ‹ λ“± μ μ™Έ)
"""

# ν•µμ‹¬ ν•¨μλ“¤ (core.py)
from .core import (
    pseudonymize_text,
    pseudonymize_text_with_fake,
    restore_original,
    restore_original_enhanced,  # β­ μƒλ΅ μ¶”κ°€
    workflow_process_ai_response,
    get_data_pool_stats,
    create_enhanced_substitution_map,  # β­ μƒλ΅ μ¶”κ°€
    apply_enhanced_substitutions  # β­ μƒλ΅ μ¶”κ°€
)

# λ°μ΄ν„°ν’€ (pools.py)
from .pools import (
    get_pools,
    initialize_pools,
    NAME_EXCLUDE_WORDS
)

# PII νƒμ§€ (normalizers.pyμ—μ„ ν†µν•©)
from .normalizers import (
    detect_pii_all,
    detect_emails,
    detect_phones,
    detect_names,
    detect_addresses,
    detect_ages,
    smart_clean_korean_text,  # β­ μƒλ΅ μ¶”κ°€
    is_valid_korean_name,  # β­ μƒλ΅ μ¶”κ°€
    # νΈν™μ„± ν•¨μλ“¤
    detect_pii_enhanced,
    detect_with_ner,
    detect_with_regex,
    detect_names_from_csv,
    detect_addresses_from_csv,
    merge_detections
)

# λ§¤λ‹μ € (manager.py)
from .manager import (
    get_manager,
    is_manager_ready,
    get_manager_status
)

# λ²„μ „ μ •λ³΄ (μ—…λ°μ΄νΈ)
__version__ = "4.2.0"  # κ°•ν™”λ μ—­λ³µνΈν™” λ²„μ „
__title__ = "GenAI Pseudonymizer (AenganZ Enhanced) - Enhanced Reverse Decryption"
__description__ = "AI μ„λΉ„μ¤μ© κ°μΈμ •λ³΄ κ°€λ…ν™” μ‹μ¤ν… (κ°•ν™”λ μ—­λ³µνΈν™” λ²„μ „)"
__author__ = "AenganZ Development Team"

# ν™•μ¥λ κ³µκ° API
__all__ = [
    # ν•µμ‹¬ ν•¨μλ“¤ (κ°•ν™”λ¨)
    'pseudonymize_text',
    'pseudonymize_text_with_fake',
    'restore_original',
    'restore_original_enhanced',  # β­ μƒλ΅ μ¶”κ°€
    'workflow_process_ai_response',
    'get_data_pool_stats',
    'create_enhanced_substitution_map',  # β­ μƒλ΅ μ¶”κ°€
    'apply_enhanced_substitutions',  # β­ μƒλ΅ μ¶”κ°€
    
    # λ°μ΄ν„°ν’€
    'get_pools',
    'initialize_pools',
    'NAME_EXCLUDE_WORDS',
    
    # PII νƒμ§€ (κ°•ν™”λ¨)
    'detect_pii_all',
    'detect_emails',
    'detect_phones', 
    'detect_names',
    'detect_addresses',
    'detect_ages',
    'smart_clean_korean_text',  # β­ μƒλ΅ μ¶”κ°€
    'is_valid_korean_name',  # β­ μƒλ΅ μ¶”κ°€
    'detect_pii_enhanced',  # νΈν™μ„±
    'detect_with_ner',      # νΈν™μ„±
    'detect_with_regex',    # νΈν™μ„±
    'detect_names_from_csv', # νΈν™μ„±
    'detect_addresses_from_csv', # νΈν™μ„±
    'merge_detections',     # νΈν™μ„±
    
    # λ§¤λ‹μ €
    'get_manager',
    'is_manager_ready',
    'get_manager_status',
    
    # λ©”νƒ€λ°μ΄ν„°
    '__version__',
    '__title__',
    '__description__',
    '__author__'
]

def print_info():
    """μ •λ³΄ μ¶λ ¥ (μ—…λ°μ΄νΈ)"""
    print(f"{__title__} v{__version__}")
    print(f"{__description__}")
    print(f"μ‘μ„±μ: {__author__}")
    print()
    print("β­ κ°•ν™”λ μ—­λ³µνΈν™” κΈ°λ¥:")
    print("  - ν•κµ­μ–΄ μ΅°μ‚¬ μΈμ‹ λ° μ²λ¦¬ (λ‹, μ”¨, μ΄, κ°€, μ„, λ¥Ό λ“±)")
    print("  - 1:1 λ§¤ν•‘ μ „λµμΌλ΅ μ •ν™•ν• λ³µμ›")
    print("  - μ΅΄μΉ­ λ³΄μ΅΄ μ²λ¦¬")
    print("  - λ¬Έλ§¥μ  ν¨ν„΄ λ§¤μΉ­")
    print()
    print("μ£Όμ” κΈ°λ¥:")
    print("  - μ‹¤μ  κ°€λ… μΉν™ (κΉ€κ°€λ…, μ΄κ°€λ… λ“±)")
    print("  - κ°•ν™”λ PII νƒμ§€ (μ΄λ©”μΌ, μ „ν™”λ²νΈ, μ΄λ¦„, μ£Όμ†, λ‚μ΄)")
    print("  - μ¤λ§νΈ μ£Όμ† μ²λ¦¬ (κ°λ³„ λ§¤ν•‘)")
    print("  - μΌλ°λ…μ‚¬ ν•„ν„°λ§ (κ³ κ°, μ†λ‹ λ“± μ μ™Έ)")
    print("  - Flask κΈ°λ° μ„λ²„ νΈν™")
    print("  - λΈλΌμ°μ € ν™•μ¥ ν”„λ΅κ·Έλ¨ νΈν™")
    print()
    print("μ‚¬μ©λ²•:")
    print("  from pseudonymization import pseudonymize_text_with_fake, restore_original_enhanced")
    print("  result = pseudonymize_text_with_fake('κΉ€μ² μλ‹μ΄ λ¶€μ‚°μ—μ„ μ‚΄κ³  μμµλ‹λ‹¤')")
    print("  restored = restore_original_enhanced(ai_response, result['reverse_map'])")
    print()
    print("μ—­λ³µνΈν™” ν…μ¤νΈ:")
    print("  μ…λ ¥: 'κΉ€μ² μλ‹μ΄ λ¶€μ‚° ν•΄μ΄λ€κµ¬μ—μ„ μ‚΄κ³  μμµλ‹λ‹¤'")
    print("  κ°€λ…ν™”: 'κΉ€κ°€λ…λ‹μ΄ μ„μΈ κ°•λ‚¨κµ¬μ—μ„ μ‚΄κ³  μμµλ‹λ‹¤'")
    print("  AIμ‘λ‹µ: 'κΉ€κ°€λ…λ‹κ»μ„ μ„μΈ κ°•λ‚¨κµ¬μ— κ±°μ£Όν•μ‹λ”κµ°μ”'")
    print("  λ³µμ›: 'κΉ€μ² μλ‹κ»μ„ λ¶€μ‚° ν•΄μ΄λ€κµ¬μ— κ±°μ£Όν•μ‹λ”κµ°μ”'")

def test_enhanced_restoration():
    """κ°•ν™”λ λ³µμ› κΈ°λ¥ ν…μ¤νΈ"""
    print("π§ κ°•ν™”λ λ³µμ› κΈ°λ¥ ν…μ¤νΈ μ‹μ‘...")
    
    # ν…μ¤νΈ λ°μ΄ν„°
    test_cases = [
        {
            "name": "μ΄λ¦„ + μ΅΄μΉ­",
            "original": "κΉ€μ² μλ‹μ΄ λ¬Έμν–μµλ‹λ‹¤",
            "fake_map": {"κΉ€κ°€λ…": "κΉ€μ² μ"},
            "ai_response": "κΉ€κ°€λ…λ‹μ λ¬Έμλ¥Ό ν™•μΈν–μµλ‹λ‹¤",
            "expected": "κΉ€μ² μλ‹μ λ¬Έμλ¥Ό ν™•μΈν–μµλ‹λ‹¤"
        },
        {
            "name": "μ£Όμ† κ°λ³„ λ§¤ν•‘",
            "original": "λ¶€μ‚° ν•΄μ΄λ€κµ¬μ—μ„ μ‚΄κ³  μμµλ‹λ‹¤",
            "fake_map": {"μ„μΈ": "λ¶€μ‚°", "κ°•λ‚¨κµ¬": "ν•΄μ΄λ€κµ¬"},
            "ai_response": "μ„μΈ κ°•λ‚¨κµ¬λ” μΆ‹μ€ κ³³μ΄λ„¤μ”",
            "expected": "λ¶€μ‚° ν•΄μ΄λ€κµ¬λ” μΆ‹μ€ κ³³μ΄λ„¤μ”"
        },
        {
            "name": "μ „ν™”λ²νΈ",
            "original": "010-1234-5678λ΅ μ—°λ½μ£Όμ„Έμ”",
            "fake_map": {"010-0000-0001": "010-1234-5678"},
            "ai_response": "010-0000-0001λ΅ μ—°λ½λ“λ¦¬κ² μµλ‹λ‹¤",
            "expected": "010-1234-5678λ΅ μ—°λ½λ“λ¦¬κ² μµλ‹λ‹¤"
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nν…μ¤νΈ {i}: {test_case['name']}")
        print(f"  AI μ‘λ‹µ: {test_case['ai_response']}")
        
        try:
            restored = restore_original_enhanced(test_case['ai_response'], test_case['fake_map'])
            print(f"  λ³µμ› κ²°κ³Ό: {restored}")
            print(f"  μμƒ κ²°κ³Ό: {test_case['expected']}")
            
            if restored == test_case['expected']:
                print(f"  β… μ„±κ³µ")
            else:
                print(f"  β μ‹¤ν¨")
        except Exception as e:
            print(f"  π’¥ μ¤λ¥: {e}")
    
    print("\nπ§ ν…μ¤νΈ μ™„λ£")

# λ¨λ“ λ΅λ“ μ‹ μ •λ³΄ μ¶λ ¥ (μ„ νƒμ )
if __name__ == "__main__":
    print_info()
    test_enhanced_restoration()