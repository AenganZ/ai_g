# pseudonymization/core.py - ê°œì„ ëœ PII íƒì§€ ë¡œì§
import os
import re
import random
from typing import List, Dict, Any, Optional

# ===== ì •ê·œì‹ íŒ¨í„´ (ê°œì„ ëœ ë²„ì „) =====
EMAIL_PATTERN = re.compile(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}')
PHONE_PATTERN = re.compile(r'010[-\s]?\d{4}[-\s]?\d{4}')
AGE_PATTERN = re.compile(r'\b(\d{1,2})\s*(?:ì„¸|ì‚´)\b')

# ê°•í™”ëœ ì´ë¦„ íŒ¨í„´
NAME_PATTERNS = [
    re.compile(r'ì´ë¦„ì€\s*([ê°€-í£]{2,4})'),
    re.compile(r'([ê°€-í£]{2,4})\s*ì…ë‹ˆë‹¤'),
    re.compile(r'ì €ëŠ”\s*([ê°€-í£]{2,4})'),
    re.compile(r'([ê°€-í£]{2,4})(?:ì´ì—ìš”|ì˜ˆìš”|ì´ì•¼|ì•¼)'),
    re.compile(r'([ê°€-í£]{2,4})(?:ì…ë‹ˆë‹¤|ì´ë‹¤)'),
    re.compile(r'ì•ˆë…•í•˜ì„¸ìš”,?\s*(?:ì €ëŠ”\s*)?([ê°€-í£]{2,4})'),
    re.compile(r'([ê°€-í£]{2,4})ì´ê³ '),
    re.compile(r'([ê°€-í£]{2,4})ì´ë©°'),
    re.compile(r'([ê°€-í£]{2,4})ë¼ê³ \s*í•©ë‹ˆë‹¤'),
    re.compile(r'([ê°€-í£]{2,4})ë¼ê³ \s*í•´ìš”'),
    re.compile(r'([ê°€-í£]{2,4})(?:ë‹˜|ì”¨)'),
]

# ê°œì„ ëœ ì£¼ì†Œ íŒ¨í„´ (ë” ì •í™•í•˜ê²Œ)
ADDRESS_PATTERNS = [
    # ì™„ì „í•œ ì£¼ì†Œ í˜•íƒœ (ì‹œ/ë„ + êµ¬/êµ° + ë™/ë¡œ)
    re.compile(r'([ê°€-í£]+(?:ì‹œ|ë„|íŠ¹ë³„ì‹œ|ê´‘ì—­ì‹œ|íŠ¹ë³„ìì¹˜ì‹œ|íŠ¹ë³„ìì¹˜ë„))\s*([ê°€-í£]+(?:êµ¬|êµ°))\s*([ê°€-í£]+(?:ë™|ë¡œ|ê°€))'),
    
    # ì‹œ/ë„ + êµ¬/êµ° í˜•íƒœ
    re.compile(r'([ê°€-í£]+(?:ì‹œ|ë„|íŠ¹ë³„ì‹œ|ê´‘ì—­ì‹œ|íŠ¹ë³„ìì¹˜ì‹œ|íŠ¹ë³„ìì¹˜ë„))\s*([ê°€-í£]+(?:êµ¬|êµ°))'),
    
    # ë‹¨ë… ì‹œ/ë„ (í•˜ì§€ë§Œ ì£¼ì†Œ ë§¥ë½ì—ì„œë§Œ)
    re.compile(r'(?:ê±°ì£¼|ì‚´ê³ |ìœ„ì¹˜|ìˆëŠ”|ì§€ì—­)\s*[ê°€-í£]*\s*([ê°€-í£]+(?:ì‹œ|ë„|íŠ¹ë³„ì‹œ|ê´‘ì—­ì‹œ|íŠ¹ë³„ìì¹˜ì‹œ|íŠ¹ë³„ìì¹˜ë„))'),
    
    # êµ¬/êµ°ë§Œ (ì‹œ/ë„ê°€ ì•ì— ì–¸ê¸‰ëœ ê²½ìš°)
    re.compile(r'(?<=ì‹œ)\s*([ê°€-í£]+(?:êµ¬|êµ°))'),
    re.compile(r'(?<=ë„)\s*([ê°€-í£]+(?:êµ¬|êµ°))'),
]

# ì£¼ì†Œê°€ ì•„ë‹Œ ë‹¨ì–´ë“¤ ì œì™¸ ë¦¬ìŠ¤íŠ¸
ADDRESS_EXCLUDE_WORDS = {
    'ê±°ì£¼í•˜ì‹œ', 'ë¶„ì´ì‹œ', 'í•˜ì‹œëŠ”', 'ìˆëŠ”', 'ê³„ì‹œëŠ”', 'ì‚´ê³ ', 'ìœ„ì¹˜í•œ', 
    'ì§€ì—­ì€', 'ë™ë„¤ëŠ”', 'ê·¼ì²˜ëŠ”', 'ì¼ëŒ€ëŠ”', 'ìª½ì€', 'ë°©ë©´ì€'
}

# ===== ë°ì´í„°í’€ ì €ì¥ì†Œ =====
name_pool = []
full_name_pool = []
fake_name_pool = []
email_pool = []
phone_pool = []
address_pool = []
company_pool = []

def load_data_pools():
    """ëª¨ë“  ë°ì´í„°í’€ ì´ˆê¸°í™”"""
    global name_pool, full_name_pool, fake_name_pool
    global email_pool, phone_pool, address_pool, company_pool
    
    print("ğŸ“‚ ë°ì´í„°í’€ ë¡œë”© ì¤‘...")
    
    # ì´ë¦„í’€ ë¡œë“œ (name.csvê°€ ìˆìœ¼ë©´ ì‚¬ìš©)
    try:
        if os.path.exists('name.csv'):
            import pandas as pd
            df = pd.read_csv('name.csv', encoding='utf-8')
            name_pool = df['ì´ë¦„'].tolist()[:1000]  # ìµœëŒ€ 1000ê°œ
            print(f"âœ… name.csvì—ì„œ {len(name_pool)}ê°œ ì´ë¦„ ë¡œë“œ")
        else:
            # ê¸°ë³¸ ì´ë¦„í’€
            name_pool = [
                'ë¯¼ì¤€', 'ì„œì¤€', 'ë„ìœ¤', 'ì˜ˆì¤€', 'ì‹œìš°', 'ì£¼ì›', 'í•˜ì¤€', 'ì§€í˜¸',
                'ì§€í›„', 'ì¤€ìš°', 'í˜„ìš°', 'ì¤€ì„œ', 'ë„í˜„', 'ì§€í›ˆ', 'ê±´ìš°', 'ìš°ì§„',
                'ì„œìœ¤', 'ì§€ìš°', 'ì„œí˜„', 'í•˜ì€', 'ì˜ˆì€', 'ìœ¤ì„œ', 'ì§€ë¯¼', 'ì±„ì›'
            ]
            print(f"âœ… ê¸°ë³¸ ì´ë¦„í’€ ì‚¬ìš©: {len(name_pool)}ê°œ")
    except Exception as e:
        print(f"âŒ ì´ë¦„í’€ ë¡œë“œ ì‹¤íŒ¨: {e}")
        name_pool = ['ë¯¼ì¤€', 'ì„œì¤€', 'ì§€ìš°', 'ì„œí˜„']
    
    # í•œêµ­ ì„±ì”¨
    surnames = [
        'ê¹€', 'ì´', 'ë°•', 'ìµœ', 'ì •', 'ê°•', 'ì¡°', 'ìœ¤', 'ì¥', 'ì„',
        'í•œ', 'ì˜¤', 'ì„œ', 'ì‹ ', 'ê¶Œ', 'í™©', 'ì•ˆ', 'ì†¡', 'ë¥˜', 'ì „'
    ]
    
    # ì„±+ì´ë¦„ ì¡°í•© ìƒì„±
    full_name_pool = []
    for surname in surnames:
        for name in name_pool[:50]:  # ë©”ëª¨ë¦¬ ì ˆì•½
            full_name_pool.append(surname + name)
    
    # ê°€ëª… ì´ë¦„ í’€ ìƒì„±
    fake_words = ['ê°€ëª…', 'ìµëª…', 'ë¬´ëª…', 'ì°¨ëª…', 'ë³„ëª…', 'í…ŒìŠ¤íŠ¸', 'ìƒ˜í”Œ', 'ë”ë¯¸']
    fake_name_pool = [surname + fake_word for surname in surnames for fake_word in fake_words]
    
    # ì´ë©”ì¼í’€ ìƒì„±
    email_domains = ['gmail.com', 'naver.com', 'daum.net', 'kakao.com']
    email_prefixes = ['user', 'test', 'hello', 'work', 'info', 'office']
    email_pool = []
    for i in range(100):
        prefix = random.choice(email_prefixes) + str(i + 1000)
        domain = random.choice(email_domains)
        email_pool.append(f"{prefix}@{domain}")
    
    # ì „í™”ë²ˆí˜¸í’€ ìƒì„±
    phone_pool = [f"010-{i//100:04d}-{i%100:04d}" for i in range(1000, 2000)]
    
    # ì£¼ì†Œí’€ ìƒì„±
    address_pool = [
        'ì„œìš¸ì‹œ ê°•ë‚¨êµ¬', 'ì„œìš¸ì‹œ ì„œì´ˆêµ¬', 'ì„œìš¸ì‹œ ì†¡íŒŒêµ¬', 'ì„œìš¸ì‹œ ê°•ë™êµ¬',
        'ì„œìš¸ì‹œ ë§ˆí¬êµ¬', 'ì„œìš¸ì‹œ ìš©ì‚°êµ¬', 'ë¶€ì‚°ì‹œ í•´ìš´ëŒ€êµ¬', 'ë¶€ì‚°ì‹œ ë¶€ì‚°ì§„êµ¬',
        'ëŒ€êµ¬ì‹œ ì¤‘êµ¬', 'ëŒ€êµ¬ì‹œ ë™êµ¬', 'ì¸ì²œì‹œ ë‚¨ë™êµ¬', 'ì¸ì²œì‹œ ë¶€í‰êµ¬',
        'ê²½ê¸°ë„ ìˆ˜ì›ì‹œ', 'ê²½ê¸°ë„ ì„±ë‚¨ì‹œ', 'ëŒ€ì „ì‹œ ì„œêµ¬', 'ê´‘ì£¼ì‹œ ì„œêµ¬'
    ]
    
    # ë„ë¡œëª… í’€ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
    try:
        if os.path.exists('address_road.csv'):
            import pandas as pd
            df = pd.read_csv('address_road.csv', encoding='utf-8')
            road_names = df['ë„ë¡œëª…'].dropna().unique().tolist()[:100]  # ìƒìœ„ 100ê°œ
            
            # ê¸°ì¡´ ì£¼ì†Œì— ë„ë¡œëª… ì¶”ê°€
            for base in address_pool[:5]:  # ìƒìœ„ 5ê°œ ì§€ì—­ë§Œ
                for road in road_names[:10]:  # ìƒìœ„ 10ê°œ ë„ë¡œëª…
                    address_pool.append(f"{base} {road}")
            print(f"âœ… address_road.csvì—ì„œ {len(road_names)}ê°œ ë„ë¡œëª… ë¡œë“œ")
    except Exception as e:
        print(f"âš ï¸ ë„ë¡œëª… ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # íšŒì‚¬í’€ ìƒì„±
    company_pool = [
        'ì‚¼ì„±ì „ì', 'LGì „ì', 'SKí•˜ì´ë‹‰ìŠ¤', 'í˜„ëŒ€ìë™ì°¨', 'KIA', 'í¬ìŠ¤ì½”',
        'ë„·ë§ˆë¸”', 'ì¹´ì¹´ì˜¤', 'ë„¤ì´ë²„', 'ì¿ íŒ¡', 'ë°°ë‹¬ì˜ë¯¼ì¡±', 'í† ìŠ¤'
    ]
    
    print(f"âœ… ë°ì´í„°í’€ ë¡œë“œ ì™„ë£Œ")
    print(f"   ğŸ“› ì´ë¦„: {len(name_pool)}ê°œ")
    print(f"   ğŸ‘¤ ì„±+ì´ë¦„: {len(full_name_pool)}ê°œ")
    print(f"   ğŸ­ ê°€ëª…ì´ë¦„: {len(fake_name_pool)}ê°œ")
    print(f"   ğŸ  ì£¼ì†Œ: {len(address_pool)}ê°œ")

def detect_pii_enhanced(text: str) -> List[Dict[str, Any]]:
    """ê°•í™”ëœ PII íƒì§€ (ê°œì„ ëœ ì£¼ì†Œ íƒì§€)"""
    items = []
    
    print(f"ğŸ” PII ë¶„ì„: {text[:50]}...")
    
    # 1. NER ëª¨ë¸ ì‚¬ìš© (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
    try:
        from .model import extract_entities_with_ner, is_ner_loaded
        
        if is_ner_loaded():
            ner_items = extract_entities_with_ner(text)
            items.extend(ner_items)
    except Exception as e:
        print(f"âš ï¸ NER ëª¨ë¸ ì‚¬ìš© ì‹¤íŒ¨: {e}")
    
    # 2. ì •ê·œì‹ ê¸°ë°˜ íƒì§€
    # ì´ë©”ì¼
    for match in EMAIL_PATTERN.finditer(text):
        items.append({
            "type": "ì´ë©”ì¼",
            "value": match.group(),
            "start": match.start(),
            "end": match.end(),
            "confidence": 1.0,
            "source": "Regex"
        })
    
    # ì „í™”ë²ˆí˜¸
    for match in PHONE_PATTERN.finditer(text):
        items.append({
            "type": "ì „í™”ë²ˆí˜¸",
            "value": match.group(),
            "start": match.start(),
            "end": match.end(),
            "confidence": 1.0,
            "source": "Regex"
        })
    
    # ë‚˜ì´
    for match in AGE_PATTERN.finditer(text):
        items.append({
            "type": "ë‚˜ì´",
            "value": match.group(1),
            "start": match.start(),
            "end": match.end(),
            "confidence": 0.9,
            "source": "Regex"
        })
    
    # ì´ë¦„ íŒ¨í„´
    for pattern in NAME_PATTERNS:
        for match in pattern.finditer(text):
            name = match.group(1)
            if len(name) >= 2 and len(name) <= 4:
                # ì¼ë°˜ì ì¸ ë‹¨ì–´ëŠ” ì œì™¸
                if name not in {'ê·¸ë¶„', 'ì €í¬', 'ìš°ë¦¬', 'ì—¬ê¸°', 'ê±°ê¸°', 'ì €ê¸°'}:
                    items.append({
                        "type": "ì´ë¦„",
                        "value": name,
                        "start": match.start(1),
                        "end": match.end(1),
                        "confidence": 0.75,
                        "source": "Pattern"
                    })
    
    # ê°œì„ ëœ ì£¼ì†Œ íŒ¨í„´
    for pattern in ADDRESS_PATTERNS:
        for match in pattern.finditer(text):
            # ë§¤ì¹˜ëœ ê·¸ë£¹ë“¤ í™•ì¸
            groups = match.groups()
            if groups:
                # ë§ˆì§€ë§‰ ê·¸ë£¹ì´ ì‹¤ì œ ì£¼ì†Œ ë¶€ë¶„
                address_part = groups[-1] if groups[-1] else match.group()
                
                # ì œì™¸ ë‹¨ì–´ ì²´í¬
                if address_part not in ADDRESS_EXCLUDE_WORDS:
                    items.append({
                        "type": "ì£¼ì†Œ",
                        "value": address_part,
                        "start": match.start(),
                        "end": match.end(),
                        "confidence": 0.9,
                        "source": "Regex"
                    })
    
    # 3. ë°ì´í„°í’€ ê¸°ë°˜ íƒì§€ (ì„±+ì´ë¦„ ì¡°í•©)
    if full_name_pool:
        for full_name in full_name_pool[:200]:  # ì„±ëŠ¥ì„ ìœ„í•´ ì œí•œ
            if full_name in text:
                start_idx = text.find(full_name)
                items.append({
                    "type": "ì´ë¦„",
                    "value": full_name,
                    "start": start_idx,
                    "end": start_idx + len(full_name),
                    "confidence": 0.8,
                    "source": "FullNamePool"
                })
    
    # ì¤‘ë³µ ì œê±° ë° ì •ë ¬ (ë” ì •êµí•œ ì¤‘ë³µ ì œê±°)
    unique_items = []
    seen = set()
    
    # ì •ë ¬ (ì‹œì‘ ìœ„ì¹˜ ê¸°ì¤€)
    sorted_items = sorted(items, key=lambda x: x['start'])
    
    for item in sorted_items:
        # ì¤‘ë³µ ì œê±° í‚¤: íƒ€ì…, ê°’, ëŒ€ëµì ì¸ ìœ„ì¹˜
        key = (item['type'], item['value'])
        
        # ì´ë¯¸ ìˆëŠ” í•­ëª©ê³¼ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸
        overlaps = False
        for existing_item in unique_items:
            if (existing_item['type'] == item['type'] and 
                abs(existing_item['start'] - item['start']) < 10):  # 10ì ì´ë‚´ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼
                overlaps = True
                # ë” ì‹ ë¢°ë„ê°€ ë†’ì€ ê²ƒì„ ì„ íƒ
                if item['confidence'] > existing_item['confidence']:
                    unique_items.remove(existing_item)
                    unique_items.append(item)
                break
        
        if not overlaps and key not in seen:
            seen.add(key)
            unique_items.append(item)
    
    print(f"âœ… ì´ {len(unique_items)}ê°œ PII íƒì§€ë¨")
    
    # ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
    for item in unique_items:
        print(f"   {item['type']}: '{item['value']}' (ì‹ ë¢°ë„: {item['confidence']:.2f}, ì†ŒìŠ¤: {item['source']})")
    
    return unique_items

def assign_realistic_values(items: List[Dict[str, Any]]) -> Dict[str, str]:
    """ì‹¤ì œ ë°ì´í„°í’€ì—ì„œ ëŒ€ì²´ê°’ í• ë‹¹"""
    substitution_map = {}
    
    for item in items:
        pii_type = item['type']
        original_value = item['value']
        
        if original_value in substitution_map:
            # ì´ë¯¸ í• ë‹¹ëœ ê°’ì´ ìˆìœ¼ë©´ ê¸°ì¡´ ê°’ ì‚¬ìš©
            item['replacement'] = substitution_map[original_value]
            continue
        
        # íƒ€ì…ë³„ ëŒ€ì²´ê°’ ìƒì„±
        if pii_type == "ì´ë¦„":
            replacement = random.choice(fake_name_pool) if fake_name_pool else "ê¹€ê°€ëª…"
        elif pii_type == "ì´ë©”ì¼":
            replacement = random.choice(email_pool) if email_pool else "test@example.com"
        elif pii_type == "ì „í™”ë²ˆí˜¸":
            replacement = random.choice(phone_pool) if phone_pool else "010-0000-0000"
        elif pii_type == "ì£¼ì†Œ":
            replacement = random.choice(address_pool) if address_pool else "ì„œìš¸ì‹œ ê°•ë‚¨êµ¬"
        elif pii_type == "íšŒì‚¬":
            replacement = random.choice(company_pool) if company_pool else "í…ŒìŠ¤íŠ¸íšŒì‚¬"
        elif pii_type == "ë‚˜ì´":
            replacement = str(random.randint(20, 65))
        else:
            replacement = f"[{pii_type.upper()}_MASKED]"
        
        # ë§¤í•‘ì— ì¶”ê°€
        substitution_map[original_value] = replacement
        # ì•„ì´í…œì—ë„ ì§ì ‘ í• ë‹¹ (ì¤‘ìš”!)
        item['replacement'] = replacement
        
        print(f"   í• ë‹¹: {original_value} â†’ {replacement}")
    
    return substitution_map

def create_masked_text(original_text: str, items: List[Dict[str, Any]]) -> str:
    """ë§ˆìŠ¤í‚¹ëœ í…ìŠ¤íŠ¸ ìƒì„±"""
    replacements = [(item['value'], item.get('replacement', 'MASKED')) 
                   for item in items if item['value']]
    
    # ê¸´ ê²ƒë¶€í„° ì¹˜í™˜ (ë¶€ë¶„ ë§¤ì¹­ ë°©ì§€)
    replacements.sort(key=lambda x: len(x[0]), reverse=True)
    
    masked_text = original_text
    for original, replacement in replacements:
        masked_text = masked_text.replace(original, replacement)
    
    return masked_text

def pseudonymize_text(original_prompt: str) -> Dict[str, Any]:
    """ë©”ì¸ ê°€ëª…í™” í•¨ìˆ˜"""
    try:
        # PII íƒì§€
        items = detect_pii_enhanced(original_prompt)
        
        # ì‹¤ì œ ë°ì´í„°í’€ì—ì„œ ëŒ€ì²´ê°’ í• ë‹¹
        substitution_map = assign_realistic_values(items)
        
        # ë³µêµ¬ìš© ë§µ ìƒì„± (ê°€ëª… â†’ ì›ë³¸)
        reverse_map = {v: k for k, v in substitution_map.items()}
        
        # ë§ˆìŠ¤í‚¹ëœ í…ìŠ¤íŠ¸ ìƒì„±
        masked_prompt = create_masked_text(original_prompt, items)
        
        detection = {
            "contains_pii": len(items) > 0,
            "items": items,
            "model_used": "Enhanced NER + Improved Regex + NamePool + FullNamePool"
        }
        
        return {
            "masked_prompt": masked_prompt,
            "detection": detection,
            "substitution_map": substitution_map,
            "reverse_map": reverse_map
        }
    
    except Exception as e:
        print(f"âŒ ê°€ëª…í™” ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        
        return {
            "masked_prompt": original_prompt,
            "detection": {"contains_pii": False, "items": []},
            "substitution_map": {},
            "reverse_map": {}
        }

def get_data_pool_stats() -> Dict[str, int]:
    """ë°ì´í„°í’€ í†µê³„ ë°˜í™˜"""
    return {
        "names": len(name_pool),
        "full_names": len(full_name_pool),
        "fake_names": len(fake_name_pool),
        "emails": len(email_pool),
        "phones": len(phone_pool),
        "addresses": len(address_pool),
        "companies": len(company_pool)
    }