# pseudonymization/detection.py
"""
PII íƒì§€ ëª¨ë“ˆ
CSV íŒŒì¼(name.csv, address_road.csv)ì„ í™œìš©í•œ ì •í™•í•œ íƒì§€
"""

import os
import re
from typing import List, Dict, Any, Set
from .pools import get_pools, COMPOUND_SURNAMES, SINGLE_SURNAMES

# ==================== CSV ë°ì´í„° ë¡œë” ====================
class DetectionData:
    """íƒì§€ìš© ë°ì´í„° ê´€ë¦¬"""
    
    def __init__(self):
        self.real_names: Set[str] = set()  # name.csvì—ì„œ ë¡œë“œí•œ ì‹¤ì œ ì´ë¦„ë“¤
        self.real_addresses: Set[str] = set()  # address_road.csvì—ì„œ ë¡œë“œí•œ ì‹¤ì œ ì£¼ì†Œë“¤
        self.road_names: Set[str] = set()  # ë„ë¡œëª…ë§Œ
        self.districts: Set[str] = set()  # ì‹œêµ°êµ¬ë§Œ
        self._loaded = False
    
    def load(self):
        """CSV íŒŒì¼ì—ì„œ íƒì§€ìš© ë°ì´í„° ë¡œë“œ"""
        if self._loaded:
            return
        
        print("ğŸ” íƒì§€ìš© ë°ì´í„° ë¡œë”© ì¤‘...")
        
        # name.csv ë¡œë“œ
        self._load_names()
        
        # address_road.csv ë¡œë“œ
        self._load_addresses()
        
        self._loaded = True
        print(f"âœ… íƒì§€ ë°ì´í„° ë¡œë“œ ì™„ë£Œ (ì´ë¦„: {len(self.real_names)}ê°œ, ì£¼ì†Œ: {len(self.real_addresses)}ê°œ)")
    
    def _load_names(self):
        """name.csvì—ì„œ ì‹¤ì œ ì´ë¦„ ë¡œë“œ"""
        if not os.path.exists('name.csv'):
            print("âš ï¸ name.csv ì—†ìŒ - ê¸°ë³¸ íƒì§€ ëª¨ë“œ")
            return
        
        try:
            try:
                import pandas as pd
                df = pd.read_csv('name.csv', encoding='utf-8')
                first_names = df['ì´ë¦„'].tolist()
                
                # ì„±ì”¨ì™€ ì¡°í•©í•˜ì—¬ ì „ì²´ ì´ë¦„ ìƒì„± (íƒì§€ìš©)
                all_surnames = SINGLE_SURNAMES + COMPOUND_SURNAMES
                
                for surname in all_surnames:
                    for first_name in first_names:
                        full_name = surname + first_name
                        if 2 <= len(full_name) <= 4:  # 2-4ê¸€ìë§Œ
                            self.real_names.add(full_name)
                
                # ì´ë¦„ë§Œë„ ì¶”ê°€ (ì„±ì”¨ ì—†ì´)
                for first_name in first_names:
                    if 2 <= len(first_name) <= 3:
                        self.real_names.add(first_name)
                
                print(f"   ğŸ“› name.csv: {len(first_names)}ê°œ â†’ {len(self.real_names)}ê°œ ì´ë¦„ ì¡°í•©")
                
            except ImportError:
                import csv
                with open('name.csv', 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        first_name = row['ì´ë¦„']
                        # ëª¨ë“  ì„±ì”¨ì™€ ì¡°í•©
                        for surname in SINGLE_SURNAMES + COMPOUND_SURNAMES:
                            self.real_names.add(surname + first_name)
                        # ì´ë¦„ë§Œë„ ì¶”ê°€
                        if 2 <= len(first_name) <= 3:
                            self.real_names.add(first_name)
                            
        except Exception as e:
            print(f"âŒ name.csv ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _load_addresses(self):
        """address_road.csvì—ì„œ ì‹¤ì œ ì£¼ì†Œ ë¡œë“œ"""
        if not os.path.exists('address_road.csv'):
            print("âš ï¸ address_road.csv ì—†ìŒ - ê¸°ë³¸ íƒì§€ ëª¨ë“œ")
            return
        
        try:
            try:
                import pandas as pd
                df = pd.read_csv('address_road.csv', encoding='utf-8')
                
                # ë„ë¡œëª…
                road_names = df['ë„ë¡œëª…'].dropna().unique()
                self.road_names.update(road_names)
                
                # ì‹œë„ + ì‹œêµ°êµ¬ ì¡°í•©
                for _, row in df.iterrows():
                    # ì‹œë„ë§Œ
                    self.real_addresses.add(row['ì‹œë„'])
                    
                    # ì‹œêµ°êµ¬ë§Œ
                    if pd.notna(row['ì‹œêµ°êµ¬']):
                        self.districts.add(row['ì‹œêµ°êµ¬'])
                        
                        # ì‹œë„ + ì‹œêµ°êµ¬
                        self.real_addresses.add(f"{row['ì‹œë„']} {row['ì‹œêµ°êµ¬']}")
                    
                    # ë„ë¡œëª…ê³¼ ì¡°í•©
                    if pd.notna(row['ë„ë¡œëª…']):
                        self.real_addresses.add(row['ë„ë¡œëª…'])
                        
                        # ì‹œêµ°êµ¬ + ë„ë¡œëª…
                        if pd.notna(row['ì‹œêµ°êµ¬']):
                            self.real_addresses.add(f"{row['ì‹œêµ°êµ¬']} {row['ë„ë¡œëª…']}")
                
                print(f"   ğŸ  address_road.csv: {len(road_names)}ê°œ ë„ë¡œëª…, {len(self.real_addresses)}ê°œ ì£¼ì†Œ ì¡°í•©")
                
            except ImportError:
                import csv
                with open('address_road.csv', 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        if row['ì‹œë„']:
                            self.real_addresses.add(row['ì‹œë„'])
                        if row['ì‹œêµ°êµ¬']:
                            self.districts.add(row['ì‹œêµ°êµ¬'])
                            self.real_addresses.add(f"{row['ì‹œë„']} {row['ì‹œêµ°êµ¬']}")
                        if row['ë„ë¡œëª…']:
                            self.road_names.add(row['ë„ë¡œëª…'])
                            self.real_addresses.add(row['ë„ë¡œëª…'])
                            
        except Exception as e:
            print(f"âŒ address_road.csv ë¡œë“œ ì‹¤íŒ¨: {e}")

# ì „ì—­ íƒì§€ ë°ì´í„° ì¸ìŠ¤í„´ìŠ¤
_detection_data = None

def get_detection_data() -> DetectionData:
    """íƒì§€ ë°ì´í„° ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤"""
    global _detection_data
    if _detection_data is None:
        _detection_data = DetectionData()
        _detection_data.load()
    return _detection_data

# ==================== ì •ê·œì‹ íŒ¨í„´ ====================
# ì´ë©”ì¼
EMAIL_PATTERN = re.compile(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}')

# ì „í™”ë²ˆí˜¸ (ë‹¤ì–‘í•œ í˜•ì‹)
PHONE_PATTERN = re.compile(
    r'(?:010|011|016|017|018|019|02|031|032|033|041|042|043|044|051|052|053|054|055|061|062|063|064)'
    r'[-.\s]?\d{3,4}[-.\s]?\d{4}'
)

# ë‚˜ì´
AGE_PATTERN = re.compile(r'(\d{1,3})\s*(?:ì„¸|ì‚´)')

# ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸
RRN_PATTERN = re.compile(r'\d{6}[-\s]?\d{7}')

# ì‹ ìš©ì¹´ë“œ
CARD_PATTERN = re.compile(r'\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}')

# ==================== PII íƒì§€ í•¨ìˆ˜ ====================
def detect_pii_enhanced(text: str) -> Dict[str, Any]:
    """ê°•í™”ëœ PII íƒì§€ (CSV ë°ì´í„° í™œìš©)"""
    items = []
    pools = get_pools()
    detection_data = get_detection_data()
    
    print(f"ğŸ” PII ë¶„ì„: {text[:50]}...")
    
    # 1. NER ëª¨ë¸ ì‚¬ìš©
    ner_items = detect_with_ner(text)
    items.extend(ner_items)
    
    # 2. CSV ê¸°ë°˜ ì´ë¦„ íƒì§€ (ë†’ì€ ì •í™•ë„)
    name_items = detect_names_from_csv(text, detection_data)
    items.extend(name_items)
    
    # 3. CSV ê¸°ë°˜ ì£¼ì†Œ íƒì§€ (ë†’ì€ ì •í™•ë„)
    address_items = detect_addresses_from_csv(text, detection_data)
    items.extend(address_items)
    
    # 4. ì •ê·œì‹ íŒ¨í„´ íƒì§€
    regex_items = detect_with_regex(text, pools)
    items.extend(regex_items)
    
    # 5. ì¤‘ë³µ ì œê±° ë° ë³‘í•©
    unique_items = merge_detections(items)
    
    # 6. ê²°ê³¼ ë°˜í™˜
    result = {
        "contains_pii": len(unique_items) > 0,
        "items": unique_items,
        "stats": {
            "ner": len(ner_items),
            "csv_names": len(name_items),
            "csv_addresses": len(address_items),
            "regex": len(regex_items),
            "total": len(unique_items)
        }
    }
    
    print(f"ğŸ¯ ìµœì¢… íƒì§€ ê²°ê³¼: {len(unique_items)}ê°œ")
    for idx, item in enumerate(unique_items, 1):
        print(f"   #{idx} {item['type']}: '{item['value']}' (ì‹ ë¢°ë„: {item['confidence']:.2f}, ì¶œì²˜: {item['source']})")
    
    return result

def detect_names_from_csv(text: str, detection_data: DetectionData) -> List[Dict[str, Any]]:
    """CSV ë°ì´í„° ê¸°ë°˜ ì´ë¦„ íƒì§€ (ì¡°ì‚¬ ì œê±° í¬í•¨)"""
    items = []
    
    if not detection_data.real_names:
        return items
    
    print(f"ğŸ‘¤ CSV ê¸°ë°˜ ì´ë¦„ íƒì§€ ì¤‘... ({len(detection_data.real_names)}ê°œ ì´ë¦„)")
    
    # ì¡°ì‚¬ ì œê±°ë¥¼ ìœ„í•œ íŒ¨í„´ - ë¬¸ìì—´ ì œëŒ€ë¡œ ë‹«ê¸°
    josa_pattern = re.compile(r'(ë‹˜|ì”¨|êµ°|ì–‘|ì´|ê°€|ì„|ë¥¼|ì—ê²Œ|ì—ì„œ|í•œí…Œ|ê»˜ì„œ|ê»˜|ëŠ”|ì€|ì´ê°€|ì´ë¥¼|ì´ëŠ”|ì´ì™€|ì´ì—¬|ì•„|ì•¼)$')
    
    # í…ìŠ¤íŠ¸ì—ì„œ ì‹¤ì œ ì´ë¦„ ì°¾ê¸°
    for name in detection_data.real_names:
        if name in text:
            # ëª¨ë“  ì¶œí˜„ ìœ„ì¹˜ ì°¾ê¸°
            start = 0
            while True:
                pos = text.find(name, start)
                if pos == -1:
                    break
                
                # ì´ë¦„ ë’¤ì— ì¡°ì‚¬ê°€ ìˆëŠ”ì§€ í™•ì¸
                end_pos = pos + len(name)
                actual_end = end_pos
                
                # ì¡°ì‚¬ê°€ ë¶™ì–´ìˆëŠ” ê²½ìš° ì²˜ë¦¬ (ì˜ˆ: "ì´ì˜í¬ë‹˜")
                if end_pos < len(text):
                    rest_text = text[end_pos:]
                    josa_match = josa_pattern.match(rest_text)
                    if josa_match:
                        actual_end = end_pos  # ì¡°ì‚¬ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŒ
                
                # ì• ë¬¸ì í™•ì¸ (ë‹¨ì–´ ê²½ê³„)
                before_ok = pos == 0 or not text[pos-1].isalnum()
                
                if before_ok:
                    items.append({
                        "type": "ì´ë¦„",
                        "value": name,
                        "start": pos,
                        "end": pos + len(name),
                        "confidence": 0.95,
                        "source": "CSV-Names"
                    })
                    print(f"   âœ… ì´ë¦„ íƒì§€ (CSV): '{name}'")
                
                start = pos + 1
    
    # ì¡°ì‚¬ê°€ ë¶™ì€ í˜•íƒœë„ ê²€ìƒ‰ (ì´ì˜í¬ë‹˜, ê¹€ì² ìˆ˜ì”¨ ë“±)
    for name in detection_data.real_names:
        # ì´ë¦„ + ì¡°ì‚¬ íŒ¨í„´ìœ¼ë¡œ ê²€ìƒ‰
        pattern = re.compile(f'{re.escape(name)}(ë‹˜|ì”¨|êµ°|ì–‘)')
        for match in pattern.finditer(text):
            items.append({
                "type": "ì´ë¦„",
                "value": name,  # ì´ë¦„ë§Œ ì €ì¥
                "start": match.start(),
                "end": match.start() + len(name),
                "confidence": 0.95,
                "source": "CSV-Names"
            })
            print(f"   âœ… ì´ë¦„ íƒì§€ (CSV+ì¡°ì‚¬): '{name}' from '{match.group()}'")
    
    return items

def detect_addresses_from_csv(text: str, detection_data: DetectionData) -> List[Dict[str, Any]]:
    """CSV ë°ì´í„° ê¸°ë°˜ ì£¼ì†Œ íƒì§€"""
    items = []
    
    # ì‹œ/ë„ ì´ë¦„ë“¤ (ê¸°ë³¸)
    provinces = ['ì„œìš¸', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ', 'ê´‘ì£¼', 'ëŒ€ì „', 'ìš¸ì‚°', 'ì„¸ì¢…',
                 'ê²½ê¸°', 'ê°•ì›', 'ì¶©ë¶', 'ì¶©ë‚¨', 'ì „ë¶', 'ì „ë‚¨', 'ê²½ë¶', 'ê²½ë‚¨', 'ì œì£¼']
    
    print(f"ğŸ  CSV ê¸°ë°˜ ì£¼ì†Œ íƒì§€ ì¤‘...")
    
    # 1. ì‹œ/ë„ íƒì§€ (ê¸°ë³¸)
    for province in provinces:
        if province in text:
            for match in re.finditer(re.escape(province), text):
                items.append({
                    "type": "ì£¼ì†Œ",
                    "value": province,
                    "start": match.start(),
                    "end": match.end(),
                    "confidence": 0.95,
                    "source": "Basic-Province"
                })
                print(f"   âœ… ì‹œ/ë„ íƒì§€: '{province}'")
    
    # 2. CSV ë„ë¡œëª… ì°¾ê¸°
    if detection_data.road_names:
        for road_name in detection_data.road_names:
            if road_name in text and len(road_name) >= 2:
                for match in re.finditer(re.escape(road_name), text):
                    items.append({
                        "type": "ì£¼ì†Œ",
                        "value": road_name,
                        "start": match.start(),
                        "end": match.end(),
                        "confidence": 0.95,
                        "source": "CSV-Roads"
                    })
                    print(f"   âœ… ë„ë¡œëª… íƒì§€ (CSV): '{road_name}'")
    
    # 3. ì‹œêµ°êµ¬ ì°¾ê¸°
    if detection_data.districts:
        for district in detection_data.districts:
            if district in text and len(district) >= 2:
                for match in re.finditer(re.escape(district), text):
                    items.append({
                        "type": "ì£¼ì†Œ",
                        "value": district,
                        "start": match.start(),
                        "end": match.end(),
                        "confidence": 0.9,
                        "source": "CSV-Districts"
                    })
                    print(f"   âœ… ì‹œêµ°êµ¬ íƒì§€ (CSV): '{district}'")
    
    # 4. ì¡°í•©ëœ ì£¼ì†Œ ì°¾ê¸° (ì‹œë„ + ì‹œêµ°êµ¬ ë“±)
    if detection_data.real_addresses:
        for address in detection_data.real_addresses:
            if address in text and len(address) >= 3:
                for match in re.finditer(re.escape(address), text):
                    items.append({
                        "type": "ì£¼ì†Œ",
                        "value": address,
                        "start": match.start(),
                        "end": match.end(),
                        "confidence": 0.95,
                        "source": "CSV-Addresses"
                    })
    
    return items

def detect_with_ner(text: str) -> List[Dict[str, Any]]:
    """NER ëª¨ë¸ì„ ì‚¬ìš©í•œ íƒì§€"""
    items = []
    
    try:
        from .model import extract_entities_with_ner, is_ner_loaded
        
        if is_ner_loaded():
            print("ğŸ¤– NER ëª¨ë¸ë¡œ ê°œì²´ëª… ì¶”ì¶œ ì¤‘...")
            ner_items = extract_entities_with_ner(text)
            items.extend(ner_items)
            print(f"   NER ê²°ê³¼: {len(ner_items)}ê°œ íƒì§€")
    except Exception as e:
        print(f"âš ï¸ NER ëª¨ë¸ ì‚¬ìš© ì‹¤íŒ¨: {e}")
    
    return items

def detect_with_regex(text: str, pools) -> List[Dict[str, Any]]:
    """ì •ê·œì‹ íŒ¨í„´ì„ ì‚¬ìš©í•œ íƒì§€"""
    items = []
    
    print("ğŸ” ì •ê·œì‹ íŒ¨í„´ìœ¼ë¡œ ì¶”ê°€ íƒì§€ ì¤‘...")
    
    # ì´ë©”ì¼
    for match in EMAIL_PATTERN.finditer(text):
        items.append({
            "type": "ì´ë©”ì¼",
            "value": match.group(),
            "start": match.start(),
            "end": match.end(),
            "confidence": 1.0,
            "source": "Regex"
        })
    
    # ì „í™”ë²ˆí˜¸
    for match in PHONE_PATTERN.finditer(text):
        items.append({
            "type": "ì „í™”ë²ˆí˜¸",
            "value": match.group(),
            "start": match.start(),
            "end": match.end(),
            "confidence": 1.0,
            "source": "Regex"
        })
    
    # ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸
    for match in RRN_PATTERN.finditer(text):
        items.append({
            "type": "ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸",
            "value": match.group(),
            "start": match.start(),
            "end": match.end(),
            "confidence": 1.0,
            "source": "Regex"
        })
    
    # ë‚˜ì´
    for match in AGE_PATTERN.finditer(text):
        items.append({
            "type": "ë‚˜ì´",
            "value": match.group(1),
            "start": match.start(),
            "end": match.end(),
            "confidence": 0.9,
            "source": "Regex"
        })
    
    return items

def merge_detections(items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """ì¤‘ë³µ ì œê±° ë° ë³‘í•© (CSV ìš°ì„ ìˆœìœ„ ë†’ìŒ)"""
    if not items:
        return []
    
    print("ğŸ§¹ ì¤‘ë³µ ì œê±° ë° ì •ë ¬ ì¤‘...")
    
    # ìš°ì„ ìˆœìœ„: CSV > NER > Regex
    priority_map = {
        'CSV-Names': 0,
        'CSV-Roads': 0,
        'CSV-Districts': 0,
        'CSV-Addresses': 0,
        'Basic-Province': 0,
        'NER': 1,
        'Regex': 2,
        'Pattern': 3
    }
    
    # ìœ„ì¹˜ ê¸°ë°˜ ì •ë ¬ (ìš°ì„ ìˆœìœ„ ê³ ë ¤)
    items.sort(key=lambda x: (x['start'], priority_map.get(x['source'].split('-')[0], 4)))
    
    # ê²¹ì¹˜ëŠ” íƒì§€ ì œê±° (ê°™ì€ ê°’ì€ í•˜ë‚˜ë§Œ)
    unique_items = []
    seen_values = set()
    
    for item in items:
        # ê°™ì€ ê°’ì´ ì´ë¯¸ ìˆìœ¼ë©´ ìŠ¤í‚µ
        value_key = (item['type'], item['value'])
        if value_key in seen_values:
            continue
        
        # ê²¹ì¹˜ëŠ” ìœ„ì¹˜ì˜ ë‹¤ë¥¸ ì•„ì´í…œ í™•ì¸
        overlap = False
        for existing in unique_items[:]:  # ë³µì‚¬ë³¸ìœ¼ë¡œ ìˆœíšŒ
            if item['start'] < existing['end'] and item['end'] > existing['start']:
                # ê°™ì€ ìœ„ì¹˜ì— ìˆëŠ” ê²½ìš°
                if item['start'] == existing['start'] and item['end'] == existing['end']:
                    # ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ê²ƒ ì„ íƒ
                    item_priority = priority_map.get(item['source'].split('-')[0], 4)
                    existing_priority = priority_map.get(existing['source'].split('-')[0], 4)
                    
                    if item_priority < existing_priority:
                        unique_items.remove(existing)
                        unique_items.append(item)
                        seen_values.discard((existing['type'], existing['value']))
                        seen_values.add(value_key)
                    overlap = True
                    break
        
        if not overlap:
            unique_items.append(item)
            seen_values.add(value_key)
    
    # ìµœì¢… ì •ë ¬
    unique_items.sort(key=lambda x: x['start'])
    
    return unique_items

# ==================== í…ŒìŠ¤íŠ¸ ====================
if __name__ == "__main__":
    print("ğŸ” PII íƒì§€ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ (CSV í™œìš©)")
    print("=" * 60)
    
    # CSV íŒŒì¼ í™•ì¸
    print("\nğŸ“ CSV íŒŒì¼ ìƒíƒœ:")
    print(f"   name.csv: {'âœ… ìˆìŒ' if os.path.exists('name.csv') else 'âŒ ì—†ìŒ'}")
    print(f"   address_road.csv: {'âœ… ìˆìŒ' if os.path.exists('address_road.csv') else 'âŒ ì—†ìŒ'}")
    
    # íƒì§€ ë°ì´í„° ë¡œë“œ
    detection_data = get_detection_data()
    print(f"\nğŸ“Š ë¡œë“œëœ íƒì§€ ë°ì´í„°:")
    print(f"   ì´ë¦„: {len(detection_data.real_names)}ê°œ")
    print(f"   ì£¼ì†Œ: {len(detection_data.real_addresses)}ê°œ")
    print(f"   ë„ë¡œëª…: {len(detection_data.road_names)}ê°œ")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    test_cases = [
        "ê¹€ë¯¼ì¤€ë‹˜ì´ ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œì— ì‚½ë‹ˆë‹¤. 010-1234-5678",
        "ì´ì„œì¤€ ê³ ê°ë‹˜, ë¶€ì‚°ê´‘ì—­ì‹œ í•´ìš´ëŒ€êµ¬ ì˜ˆì•½ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "ë°•ì§€ìš°ì”¨ëŠ” ëŒ€êµ¬ê´‘ì—­ì‹œ ì¤‘êµ¬ ë™ì„±ë¡œì—ì„œ ì¼í•©ë‹ˆë‹¤.",
        "ë‚¨ê¶ë¯¼ìˆ˜ë‹˜ì˜ ì—°ë½ì²˜ëŠ” 02-123-4567ì…ë‹ˆë‹¤.",
        "ì´ì˜í¬ë‹˜ 25ì„¸, ëŒ€êµ¬ ì¤‘êµ¬ ê±°ì£¼í•˜ì‹œëŠ” ë¶„ì´ì‹œì£ ?"
    ]
    
    for text in test_cases:
        print(f"\ní…ŒìŠ¤íŠ¸: {text}")
        result = detect_pii_enhanced(text)
        
        print(f"í†µê³„: NER={result['stats']['ner']}, "
              f"CSVì´ë¦„={result['stats']['csv_names']}, "
              f"CSVì£¼ì†Œ={result['stats']['csv_addresses']}, "
              f"ì •ê·œì‹={result['stats']['regex']}")
        
        if result['items']:
            for item in result['items']:
                print(f"  - {item['type']}: {item['value']} (ì¶œì²˜: {item['source']})")
        else:
            print("  íƒì§€ëœ PII ì—†ìŒ")