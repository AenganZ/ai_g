# pseudonymization/model.py - ë¼ë²¨ ë§¤í•‘ ë¬¸ì œ í•´ê²°
"""
NER ëª¨ë¸ ê´€ë¦¬ ëª¨ë“ˆ - KPF/KPF-bert-ner ë¼ë²¨ ë§¤í•‘ ìˆ˜ì •
"""

import time
from typing import List, Dict, Any, Optional

# NER ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„ íƒì )
try:
    import torch
    from transformers import (
        AutoModelForTokenClassification, 
        AutoTokenizer, 
        pipeline
    )
    NER_AVAILABLE = True
except ImportError:
    NER_AVAILABLE = False
    print("transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

# KPF BERT NER ëª¨ë¸
NER_MODELS = [
    "KPF/KPF-bert-ner",  # ë©”ì¸ ëª¨ë¸
    "monologg/koelectra-base-v3-naver-ner",  # ë°±ì—… ëª¨ë¸
]

class WorkingNERModel:
    """KPF BERT NER ëª¨ë¸ í´ë˜ìŠ¤ (ë¼ë²¨ ë§¤í•‘ ìˆ˜ì •)"""
    
    def __init__(self):
        self.model = None
        self.tokenizer = None
        self.pipeline = None
        self.device = self._get_device()
        self.loaded = False
        self.model_name = None
        self.id2label = None
        self.label_map = None  # ìˆ˜ë™ ë¼ë²¨ ë§¤í•‘ ì¶”ê°€
    
    def _get_device(self):
        """ìµœì ì˜ ë””ë°”ì´ìŠ¤ ì„ íƒ"""
        if not NER_AVAILABLE:
            return -1
            
        if torch.cuda.is_available():
            return 0  # GPU
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            return "mps"  # Apple Silicon
        else:
            return -1  # CPU
    
    def is_loaded(self) -> bool:
        """ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸"""
        return self.loaded
    
    def _create_manual_label_map(self):
        """ìˆ˜ë™ ë¼ë²¨ ë§¤í•‘ ìƒì„± (LABEL_ìˆ«ì -> ì˜ë¯¸ ìˆëŠ” ë¼ë²¨)"""
        # KPF ëª¨ë¸ì˜ ì‹¤ì œ ë¼ë²¨ ë§¤í•‘ (ì¶”ì¸¡ ê¸°ë°˜)
        # ë¡œê·¸ì—ì„œ ë³´ë©´: ê¹€ì² (LABEL_96), ë¶€ì‚°(LABEL_70), í•´ìš´ëŒ€êµ¬(LABEL_72), 010(LABEL_115)
        self.label_map = {
            # ì¸ëª… ê´€ë ¨ (LABEL_96, LABEL_246ì€ ì´ë¦„ì˜ ì¼ë¶€ë¡œ ë³´ì„)
            'LABEL_96': 'B-PER',    # ê¹€ì² 
            'LABEL_246': 'I-PER',   # ##ìˆ˜ (ì´ë¦„ ì—°ê²°)
            
            # ì§€ëª… ê´€ë ¨
            'LABEL_70': 'B-LOC',    # ë¶€ì‚° (ì§€ì—­ ì‹œì‘)
            'LABEL_72': 'I-LOC',    # í•´ìš´ëŒ€êµ¬ (ì§€ì—­ ì—°ê²°)
            
            # ì „í™”ë²ˆí˜¸ ê´€ë ¨
            'LABEL_115': 'B-PHONE', # 010 (ì „í™”ë²ˆí˜¸ ì‹œì‘)
            'LABEL_265': 'I-PHONE', # ë‚˜ë¨¸ì§€ ë²ˆí˜¸
            
            # ê¸°íƒ€/ì¼ë°˜ í…ìŠ¤íŠ¸
            'LABEL_299': 'O',       # ì¼ë°˜ í…ìŠ¤íŠ¸ (ê³ ê°ë‹˜, ì˜ˆì•½ì´... ë“±)
        }
        
        print(f"ğŸ—ºï¸ ìˆ˜ë™ ë¼ë²¨ ë§¤í•‘ ìƒì„±: {len(self.label_map)}ê°œ ë§¤í•‘")
        for label_id, mapped in self.label_map.items():
            print(f"  - {label_id} -> {mapped}")
    
    def load_model(self) -> bool:
        """KPF BERT NER ëª¨ë¸ ë¡œë“œ"""
        if not NER_AVAILABLE:
            print("NER ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤")
            return False
        
        for model_name in NER_MODELS:
            try:
                print(f"NER ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}")
                
                # í† í¬ë‚˜ì´ì €ì™€ ëª¨ë¸ ë¡œë“œ
                self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                self.model = AutoModelForTokenClassification.from_pretrained(model_name)
                self.model_name = model_name
                
                # ë¼ë²¨ ë§¤í•‘ ì €ì¥
                self.id2label = self.model.config.id2label
                print(f"ğŸ“‹ ì›ë³¸ ë¼ë²¨ ê°œìˆ˜: {len(self.id2label)}")
                
                # ìˆ˜ë™ ë§¤í•‘ ìƒì„±
                self._create_manual_label_map()
                
                # íŒŒì´í”„ë¼ì¸ ìƒì„± (aggregation_strategy ë³€ê²½)
                self.pipeline = pipeline(
                    "ner", 
                    model=self.model, 
                    tokenizer=self.tokenizer,
                    aggregation_strategy="max",  # "simple"ì—ì„œ ë³€ê²½
                    device=self.device
                )
                
                # ë””ë°”ì´ìŠ¤ ì„¤ì • ì¶œë ¥
                if self.device == 0:
                    print("ì¥ì¹˜ ì„¤ì •: GPU ì‚¬ìš©")
                elif self.device == "mps":
                    print("ì¥ì¹˜ ì„¤ì •: Apple Silicon ì‚¬ìš©")
                else:
                    print("ì¥ì¹˜ ì„¤ì •: CPU ì‚¬ìš©")
                
                # í…ŒìŠ¤íŠ¸
                test_text = "ê¹€ì² ìˆ˜ëŠ” ì„œìš¸ ê°•ë‚¨êµ¬ì— ì‚´ê³  ìˆìŠµë‹ˆë‹¤."
                test_result = self.pipeline(test_text)
                print(f"ğŸ§ª ëª¨ë¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼: {len(test_result)}ê°œ ì—”í‹°í‹° íƒì§€")
                
                self.loaded = True
                print(f"âœ… NER ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_name}")
                return True
                
            except Exception as e:
                print(f"âŒ ëª¨ë¸ {model_name} ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue
        
        print("âŒ ëª¨ë“  NER ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
        return False
    
    def extract_entities(self, text: str) -> List[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ (ë¼ë²¨ ë§¤í•‘ ê°œì„ )"""
        if not self.loaded or not self.pipeline:
            print("âš ï¸ NER ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
            return []
        
        try:
            # NER ì‹¤í–‰
            start_time = time.time()
            raw_entities = self.pipeline(text)
            processing_time = time.time() - start_time
            
            print(f"ğŸ” NER ì›ë³¸ ì¶œë ¥ (ê°„ëµ):")
            print(f"  ì…ë ¥: {text}")
            print(f"  íƒì§€ëœ ê°œìˆ˜: {len(raw_entities)}")
            
            # ê²°ê³¼ ì •ê·œí™”
            entities = []
            for i, entity in enumerate(raw_entities):
                entity_group = entity.get('entity_group', 'UNKNOWN')
                word = entity.get('word', '').replace('##', '')  # BERT í† í° ì •ë¦¬
                score = float(entity.get('score', 0.0))
                start = entity.get('start', 0)
                end = entity.get('end', 0)
                
                # ìˆ˜ë™ ë¼ë²¨ ë§¤í•‘ ì ìš©
                mapped_label = self.label_map.get(entity_group, entity_group)
                mapped_type = self._map_label_to_type(mapped_label)
                
                print(f"  [{i}] {entity_group} -> {mapped_label} -> {mapped_type}: '{word}' ({score:.3f})")
                
                if mapped_type and score > 0.8:  # ë†’ì€ ì‹ ë¢°ë„ë§Œ
                    # ì—°ì†ëœ í† í° ë³‘í•© (ê¹€ì²  + ##ìˆ˜ -> ê¹€ì² ìˆ˜)
                    if (entities and 
                        entities[-1]['type'] == mapped_type and 
                        entities[-1]['end'] == start):
                        # ì´ì „ ì—”í‹°í‹°ì™€ ë³‘í•©
                        entities[-1]['value'] += word
                        entities[-1]['text'] += word
                        entities[-1]['end'] = end
                        entities[-1]['confidence'] = max(entities[-1]['confidence'], score)
                        print(f"    ë³‘í•©ë¨: '{entities[-1]['value']}'")
                    else:
                        # ìƒˆ ì—”í‹°í‹° ì¶”ê°€
                        processed_entity = {
                            'type': mapped_type,
                            'label': mapped_type,
                            'text': word,
                            'value': word,
                            'start': start,
                            'end': end,
                            'confidence': score,
                            'model': self.model_name,
                            'original_label': entity_group
                        }
                        entities.append(processed_entity)
                        print(f"    ì¶”ê°€ë¨: {processed_entity}")
                else:
                    print(f"    ì œì™¸ë¨ (íƒ€ì…: {mapped_type}, ì ìˆ˜: {score:.3f})")
            
            print(f"ğŸ NER ì²˜ë¦¬ ì™„ë£Œ: {len(entities)}ê°œ ì—”í‹°í‹° ({processing_time:.3f}ì´ˆ)")
            return entities
            
        except Exception as e:
            print(f"âŒ NER ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _map_label_to_type(self, label: str) -> Optional[str]:
        """ë§¤í•‘ëœ ë¼ë²¨ì„ PII íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
        
        # B-, I- ì ‘ë‘ì‚¬ ì œê±°
        clean_label = label.replace('B-', '').replace('I-', '').upper()
        
        # íƒ€ì… ë§¤í•‘
        type_mapping = {
            'PER': 'ì´ë¦„',
            'PERSON': 'ì´ë¦„',
            'LOC': 'ì£¼ì†Œ', 
            'LOCATION': 'ì£¼ì†Œ',
            'ORG': 'ì¡°ì§',
            'ORGANIZATION': 'ì¡°ì§',
            'PHONE': 'ì „í™”ë²ˆí˜¸',
            'EMAIL': 'ì´ë©”ì¼',
            'MISC': 'ê¸°íƒ€'
        }
        
        return type_mapping.get(clean_label, None)

# ì „ì—­ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
_ner_model_instance = None

def get_ner_model() -> WorkingNERModel:
    """NER ëª¨ë¸ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _ner_model_instance
    
    if _ner_model_instance is None:
        _ner_model_instance = WorkingNERModel()
    
    return _ner_model_instance

def load_ner_model() -> bool:
    """NER ëª¨ë¸ ë¡œë“œ"""
    model = get_ner_model()
    return model.load_model()

def extract_entities_with_ner(text: str) -> List[Dict[str, Any]]:
    """NER ëª¨ë¸ì„ ì‚¬ìš©í•œ ê°œì²´ëª… ì¶”ì¶œ"""
    model = get_ner_model()
    
    if not model.is_loaded():
        # ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ë¡œë“œ ì‹œë„
        if not model.load_model():
            print("âŒ NER ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return []
    
    return model.extract_entities(text)

def is_ner_available() -> bool:
    """NER ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    return NER_AVAILABLE

def is_ner_loaded() -> bool:
    """NER ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸"""
    model = get_ner_model()
    return model.is_loaded()

# í˜¸í™˜ì„± í•¨ìˆ˜ë“¤
def call_qwen_detect_pii(original_prompt: str, model=None, tokenizer=None, device=None) -> Dict[str, Any]:
    """ê¸°ì¡´ í˜¸í™˜ì„ ìœ„í•œ í•¨ìˆ˜"""
    entities = extract_entities_with_ner(original_prompt)
    return {
        "items": entities,
        "contains_pii": len(entities) > 0
    }

def pick_device_and_dtype():
    """ë””ë°”ì´ìŠ¤ ë° ë°ì´í„° íƒ€ì… ì„ íƒ"""
    if not NER_AVAILABLE:
        return "cpu", None
        
    model = get_ner_model()
    device = model.device
    
    if device == 0:  # GPU
        return "cuda", torch.float16
    elif device == "mps":  # Apple Silicon
        return "mps", torch.float16
    else:  # CPU
        return "cpu", torch.float32

def load_model():
    """ëª¨ë¸ ë¡œë“œ (í˜¸í™˜ì„±)"""
    return load_ner_model()