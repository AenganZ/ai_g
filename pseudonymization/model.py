# pseudonymization/model.py - ì‹¤ì œ ì‘ë™í•˜ëŠ” í•œêµ­ì–´ NER ëª¨ë¸ë“¤
import os
import torch
import time
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor

# NER ëª¨ë¸ ê´€ë ¨ import
try:
    from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
    NER_AVAILABLE = True
except ImportError:
    NER_AVAILABLE = False
    print("âš ï¸ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. pip install transformers torchë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

# ì‹¤ì œ ì¡´ì¬í•˜ê³  ì‘ë™í•˜ëŠ” í•œêµ­ì–´ NER ëª¨ë¸ë“¤ (ê²€ì¦ë¨)
NER_MODELS = [
    # 1ìˆœìœ„: ê²€ì¦ëœ ì„±ëŠ¥ ì¢‹ì€ ëª¨ë¸ë“¤
    "monologg/koelectra-base-v3-naver-ner",     # ë„¤ì´ë²„ ë°ì´í„°, ê²€ì¦ë¨ âœ…
    "Leo97/KoELECTRA-small-v3-modu-ner",       # ëª¨ë‘ì˜ ë§ë­‰ì¹˜, ë¹ ë¦„ âœ…
    
    # 2ìˆœìœ„: ëŒ€ì•ˆ ëª¨ë¸ë“¤
    "KPF/KPF-bert-ner",                        # í•œêµ­ì–¸ë¡ ì§„í¥ì¬ë‹¨, ì‹ ë¬¸ íŠ¹í™” âœ…
    "beomi/kcbert-base",                        # KcBERT (NER íŒŒì¸íŠœë‹ í•„ìš”í•˜ì§€ë§Œ ë² ì´ìŠ¤ë¡œ ì‚¬ìš© ê°€ëŠ¥)
    
    # 3ìˆœìœ„: ë‹¤ë¥¸ ì ‘ê·¼ë²• (GLiNER ë“±)
    # "taeminlee/gliner_ko",                    # GLiNER ë°©ì‹ (ë‹¤ë¥¸ ì‚¬ìš©ë²•)
]

class WorkingNERModel:
    """ì‹¤ì œ ì‘ë™í•˜ëŠ” NER ëª¨ë¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.model = None
        self.tokenizer = None
        self.pipeline = None
        self.device = self._get_device()
        self.loaded = False
        self.model_name = None
        self.load_time = 0
        self.inference_times = []
    
    def _get_device(self):
        """ìµœì ì˜ ë””ë°”ì´ìŠ¤ ì„ íƒ"""
        if torch.cuda.is_available():
            return 0  # GPU ì‚¬ìš©
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            return "mps"  # Apple Silicon
        else:
            return -1  # CPU
    
    def load_model(self) -> bool:
        """ì‹¤ì œ ì‘ë™í•˜ëŠ” NER ëª¨ë¸ ë¡œë“œ"""
        if not NER_AVAILABLE:
            print("âŒ NER ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤")
            return False
        
        start_time = time.time()
        
        for model_name in NER_MODELS:
            try:
                print(f"ğŸ”„ NER ëª¨ë¸ ë¡œë”© ì‹œë„: {model_name}")
                
                # í† í¬ë‚˜ì´ì € ë¡œë“œ
                self.tokenizer = AutoTokenizer.from_pretrained(
                    model_name,
                    use_fast=True,
                    trust_remote_code=True
                )
                
                # ëª¨ë¸ ë¡œë“œ (dtype íŒŒë¼ë¯¸í„°ë¡œ ìˆ˜ì •)
                self.model = AutoModelForTokenClassification.from_pretrained(
                    model_name,
                    dtype=torch.float16 if self.device != -1 else torch.float32,  # torch_dtype ëŒ€ì‹  dtype ì‚¬ìš©
                    trust_remote_code=True,
                    low_cpu_mem_usage=True
                )
                
                # GPU ì‚¬ìš© ì‹œ ëª¨ë¸ ì´ë™
                if self.device != -1:
                    self.model = self.model.to(self.device)
                
                # íŒŒì´í”„ë¼ì¸ ìƒì„± (ë¬¸ì œ ìˆëŠ” íŒŒë¼ë¯¸í„° ì œê±°)
                self.pipeline = pipeline(
                    "ner", 
                    model=self.model, 
                    tokenizer=self.tokenizer,
                    aggregation_strategy="simple",
                    device=self.device,
                    # return_all_scores, batch_size, max_length ë“± ë¬¸ì œ ìˆëŠ” íŒŒë¼ë¯¸í„° ì œê±°
                )
                
                # í…ŒìŠ¤íŠ¸ ë¬¸ì¥ìœ¼ë¡œ ëª¨ë¸ ê²€ì¦
                test_text = "í™ê¸¸ë™ì€ ì„œìš¸ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œì— ì‚´ê³  ìˆìŠµë‹ˆë‹¤."
                test_start = time.time()
                test_result = self.pipeline(test_text)
                test_time = (time.time() - test_start) * 1000  # ms ë‹¨ìœ„
                
                self.loaded = True
                self.model_name = model_name
                self.load_time = time.time() - start_time
                
                print(f"âœ… NER ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_name}")
                print(f"   ğŸ“± ë””ë°”ì´ìŠ¤: {self.device}")
                print(f"   â±ï¸ ë¡œë“œ ì‹œê°„: {self.load_time:.2f}ì´ˆ")
                print(f"   ğŸš€ í…ŒìŠ¤íŠ¸ ì¶”ë¡  ì‹œê°„: {test_time:.1f}ms")
                print(f"   ğŸ§ª í…ŒìŠ¤íŠ¸ ê²°ê³¼: {len(test_result)}ê°œ ì—”í‹°í‹° íƒì§€")
                
                # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¶œë ¥
                for entity in test_result:
                    print(f"   - {entity.get('entity_group', 'N/A')}: {entity.get('word', 'N/A')} (ì‹ ë¢°ë„: {entity.get('score', 0):.3f})")
                
                return True
                
            except Exception as e:
                error_msg = str(e)
                print(f"âŒ {model_name} ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                # êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ë¶„ì„
                if "not a valid model identifier" in error_msg:
                    print(f"   ğŸ’¡ ëª¨ë¸ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ - ë‹¤ìŒ ëª¨ë¸ ì‹œë„")
                elif "unexpected keyword argument" in error_msg:
                    print(f"   ğŸ’¡ íŒŒì´í”„ë¼ì¸ íŒŒë¼ë¯¸í„° ì˜¤ë¥˜ - ë‹¤ìŒ ëª¨ë¸ ì‹œë„")
                elif "token" in error_msg and "permission" in error_msg:
                    print(f"   ğŸ’¡ ë¹„ê³µê°œ ì €ì¥ì†Œ - ë‹¤ìŒ ëª¨ë¸ ì‹œë„")
                
                continue
        
        print("âŒ ëª¨ë“  NER ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
        print("ğŸ’¡ í•´ê²° ë°©ë²•:")
        print("   1. pip install transformers torch --upgrade")
        print("   2. ì¸í„°ë„· ì—°ê²° í™•ì¸")
        print("   3. HuggingFace í† í° ì„¤ì • (í•„ìš”ì‹œ)")
        self.loaded = False
        return False
    
    def is_loaded(self) -> bool:
        """ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸"""
        return self.loaded
    
    def extract_entities(self, text: str) -> List[Dict[str, Any]]:
        """ë¹ ë¥´ê³  ì•ˆì •ì ì¸ ê°œì²´ëª… ì¶”ì¶œ"""
        if not self.loaded or not self.pipeline:
            return []
        
        start_time = time.time()
        
        try:
            # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
            if len(text) > 400:
                text = text[:400]
                print(f"âš ï¸ í…ìŠ¤íŠ¸ê°€ 400ìë¡œ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # NER ì¶”ë¡  ì‹¤í–‰ (ì•ˆì „í•œ íŒŒë¼ë¯¸í„°ë§Œ ì‚¬ìš©)
            ner_results = self.pipeline(text)
            
            # ê²°ê³¼ ì²˜ë¦¬ ë° í† í¬ë‚˜ì´ì € ì•„í‹°íŒ©íŠ¸ ë³µì›
            entities = []
            
            # ì—°ì†ëœ í† í° í•©ì¹˜ê¸° (##ë¡œ ë¶„ë¦¬ëœ ê²ƒë“¤)
            merged_results = self._merge_subword_tokens(ner_results, text)
            
            for entity in merged_results:
                entity_type = entity.get('entity_group', entity.get('entity', ''))
                entity_text = entity.get('word', '').strip()
                confidence = entity.get('score', 0.0)
                start = entity.get('start', 0)
                end = entity.get('end', 0)
                
                # í† í¬ë‚˜ì´ì € ì•„í‹°íŒ©íŠ¸ ì œê±°
                entity_text = entity_text.replace('##', '').replace('â–', ' ').strip()
                
                # ì‹ ë¢°ë„ ì„ê³„ê°’ (ì£¼ì†ŒëŠ” ë§¤ìš° ë‚®ê²Œ)
                if any(keyword in entity_type.upper() for keyword in ['LC', 'LOC', 'LOCATION']):
                    threshold = 0.5  # ì£¼ì†ŒëŠ” ë§¤ìš° ë‚®ì€ ì„ê³„ê°’
                elif any(keyword in entity_type.upper() for keyword in ['PS', 'PER', 'PERSON']):
                    threshold = 0.7  # ì´ë¦„ì€ ì¤‘ê°„ ì„ê³„ê°’
                else:
                    threshold = 0.6  # ê¸°ë³¸ ì„ê³„ê°’ (B, I íƒœê·¸ìš©)
                
                print(f"   ğŸ“Š ì—”í‹°í‹° ê²€í† : '{entity_text}' (íƒ€ì…: {entity_type}, ì‹ ë¢°ë„: {confidence:.3f}, ì„ê³„ê°’: {threshold})")
                
                if confidence > threshold and len(entity_text) >= 2:
                    pii_type = self._map_ner_label_to_pii_type(entity_type)
                    if pii_type and pii_type != 'ê¸°íƒ€':  # 'ê¸°íƒ€'ëŠ” ì œì™¸í•˜ê³  ì‹¤ì œ PIIë§Œ
                        entities.append({
                            "type": pii_type,
                            "value": entity_text,
                            "start": start,
                            "end": end,
                            "confidence": confidence,
                            "source": f"NER-{self.model_name.split('/')[-1]}"
                        })
                        print(f"   âœ… ì¶”ê°€ë¨: {pii_type} = '{entity_text}'")
                    else:
                        print(f"   âŒ ì œì™¸ë¨: ë§¤í•‘ ì‹¤íŒ¨ ë˜ëŠ” ê¸°íƒ€ íƒ€ì…")
            
            # ì„±ëŠ¥ ì¸¡ì •
            inference_time = (time.time() - start_time) * 1000
            self.inference_times.append(inference_time)
            
            print(f"ğŸ¤– NER ({self.model_name.split('/')[-1]}) íƒì§€: {len(entities)}ê°œ ({inference_time:.1f}ms)")
            return entities
            
        except Exception as e:
            print(f"âŒ NER ê°œì²´ëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def _map_ner_label_to_pii_type(self, label: str) -> Optional[str]:
        """NER ë¼ë²¨ì„ PII íƒ€ì…ìœ¼ë¡œ ë§¤í•‘ (monologg/koelectra ëª¨ë¸ íŠ¹í™”)"""
        # ì‹¤ì œ ëª¨ë¸ ì¶œë ¥ í™•ì¸ ë° ë””ë²„ê¹…
        print(f"   ğŸ” ì›ë³¸ ë¼ë²¨: '{label}'")
        
        # B-, I- ì ‘ë‘ì‚¬ ì œê±°
        clean_label = label.replace('B-', '').replace('I-', '').upper().strip()
        print(f"   ğŸ§¹ ì •ë¦¬ëœ ë¼ë²¨: '{clean_label}'")
        
        # monologg/koelectra-base-v3-naver-ner ëª¨ë¸ì˜ ì‹¤ì œ ë¼ë²¨ë“¤
        mapping = {
            # ê¸°ë³¸ BIO íƒœê·¸ë“¤ (monologg ëª¨ë¸ì—ì„œ ì‚¬ìš©)
            'B': 'ê¸°íƒ€',        # Begin (ì¼ë°˜ì ì¸ ì‹œì‘ íƒœê·¸)
            'I': 'ê¸°íƒ€',        # Inside (ì¼ë°˜ì ì¸ ë‚´ë¶€ íƒœê·¸)
            'O': None,          # Outside (ì—”í‹°í‹° ì•„ë‹˜)
            
            # ì‹¤ì œ ì—”í‹°í‹° íƒ€ì…ë“¤ (koelectra-naver-ner ê¸°ì¤€)
            'PER': 'ì´ë¦„',      # Person
            'PERSON': 'ì´ë¦„',
            'LOC': 'ì£¼ì†Œ',      # Location
            'LOCATION': 'ì£¼ì†Œ',
            'ORG': 'íšŒì‚¬',      # Organization  
            'ORGANIZATION': 'íšŒì‚¬',
            'MISC': 'ê¸°íƒ€',     # Miscellaneous
            
            # KLUE ìŠ¤íƒ€ì¼ ë¼ë²¨ë“¤
            'PS': 'ì´ë¦„',       # Person
            'LC': 'ì£¼ì†Œ',       # Location
            'OG': 'íšŒì‚¬',       # Organization
            'DT': 'ê¸°íƒ€',       # Date
            'TI': 'ê¸°íƒ€',       # Time
            'QT': 'ê¸°íƒ€',       # Quantity
            
            # í™•ì¥ ë¼ë²¨ë“¤
            'PRS': 'ì´ë¦„',
            'GPE': 'ì£¼ì†Œ',      # Geopolitical entity
            'FAC': 'ì£¼ì†Œ',      # Facility
            'DATE': 'ê¸°íƒ€',
            'TIME': 'ê¸°íƒ€',
            'MONEY': 'ê¸°íƒ€',
            'PERCENT': 'ê¸°íƒ€',
            
            # KPF-BERT-NER ë¼ë²¨ë“¤
            'PERSON_NAME': 'ì´ë¦„',
            'LOCATION_NAME': 'ì£¼ì†Œ',
            'ORGANIZATION_NAME': 'íšŒì‚¬',
        }
        
        result = mapping.get(clean_label)
        print(f"   â¡ï¸ ë§¤í•‘ ê²°ê³¼: {label} -> {result}")
        
        # ë§¤í•‘ë˜ì§€ ì•Šì€ ë¼ë²¨ ê²½ê³ 
        if result is None and clean_label not in ['O', '']:
            print(f"   âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë¼ë²¨: '{label}' ('{clean_label}')")
            # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ë¡  ì‹œë„
            if any(keyword in clean_label.lower() for keyword in ['name', 'person', 'ì´ë¦„', 'ì¸ëª…']):
                result = 'ì´ë¦„'
            elif any(keyword in clean_label.lower() for keyword in ['loc', 'location', 'place', 'ìœ„ì¹˜', 'ì£¼ì†Œ', 'ì§€ì—­']):
                result = 'ì£¼ì†Œ'  
            elif any(keyword in clean_label.lower() for keyword in ['org', 'organization', 'ê¸°ê´€', 'íšŒì‚¬']):
                result = 'íšŒì‚¬'
            else:
                result = 'ê¸°íƒ€'  # ì•Œ ìˆ˜ ì—†ëŠ” ê²ƒì€ ê¸°íƒ€ë¡œ ë¶„ë¥˜
            print(f"   ğŸ¤– ì¶”ë¡  ê²°ê³¼: {result}")
        
        return result
    
    def _merge_subword_tokens(self, ner_results: List[Dict], original_text: str) -> List[Dict]:
        """ì„œë¸Œì›Œë“œ í† í°ë“¤ì„ í•©ì³ì„œ ì™„ì „í•œ ë‹¨ì–´ë¡œ ë³µì›"""
        if not ner_results:
            return []
        
        merged = []
        current_entity = None
        
        for entity in ner_results:
            word = entity.get('word', '')
            entity_group = entity.get('entity_group', entity.get('entity', ''))
            start = entity.get('start', 0)
            end = entity.get('end', 0)
            score = entity.get('score', 0.0)
            
            # ##ë¡œ ì‹œì‘í•˜ëŠ” ì„œë¸Œì›Œë“œ í† í° ì²˜ë¦¬
            if word.startswith('##'):
                if current_entity:
                    # ì´ì „ ì—”í‹°í‹°ì™€ í•©ì¹˜ê¸°
                    current_entity['word'] += word.replace('##', '')
                    current_entity['end'] = end
                    current_entity['score'] = min(current_entity['score'], score)  # ìµœì†Œ ì‹ ë¢°ë„ ì‚¬ìš©
                continue
            
            # ìƒˆë¡œìš´ ì—”í‹°í‹° ì‹œì‘
            if current_entity:
                merged.append(current_entity)
            
            current_entity = {
                'word': word,
                'entity_group': entity_group,
                'start': start,
                'end': end,
                'score': score
            }
        
        # ë§ˆì§€ë§‰ ì—”í‹°í‹° ì¶”ê°€
        if current_entity:
            merged.append(current_entity)
        
        # ì›ë³¸ í…ìŠ¤íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ì •í™•í•œ ìœ„ì¹˜ ì¬ê³„ì‚°
        for entity in merged:
            word = entity['word'].replace('â–', ' ').strip()
            if word in original_text:
                actual_start = original_text.find(word)
                if actual_start != -1:
                    entity['start'] = actual_start
                    entity['end'] = actual_start + len(word)
            entity['word'] = word
        
        print(f"   ğŸ”§ ì„œë¸Œì›Œë“œ í•©ì¹˜ê¸°: {len(ner_results)}ê°œ -> {len(merged)}ê°œ")
        for entity in merged:
            print(f"      - {entity['entity_group']}: '{entity['word']}' (ì‹ ë¢°ë„: {entity['score']:.3f})")
        
        return merged
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        if not self.inference_times:
            return {}
        
        avg_time = sum(self.inference_times) / len(self.inference_times)
        min_time = min(self.inference_times)
        max_time = max(self.inference_times)
        
        return {
            "model_name": self.model_name,
            "device": self.device,
            "load_time": self.load_time,
            "avg_inference_time": avg_time,
            "min_inference_time": min_time,
            "max_inference_time": max_time,
            "total_inferences": len(self.inference_times)
        }

# GLiNER ëª¨ë¸ í´ë˜ìŠ¤ (ëŒ€ì•ˆ)
class GLiNERModel:
    """GLiNER ê¸°ë°˜ í•œêµ­ì–´ NER ëª¨ë¸ (ëŒ€ì•ˆ)"""
    
    def __init__(self):
        self.model = None
        self.loaded = False
        self.model_name = "taeminlee/gliner_ko"
    
    def load_model(self) -> bool:
        """GLiNER ëª¨ë¸ ë¡œë“œ"""
        try:
            from gliner import GLiNER
            print(f"ğŸ”„ GLiNER ëª¨ë¸ ë¡œë”© ì‹œë„: {self.model_name}")
            
            self.model = GLiNER.from_pretrained(self.model_name)
            self.loaded = True
            
            print(f"âœ… GLiNER ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {self.model_name}")
            return True
            
        except ImportError:
            print("âŒ GLiNER ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. pip install glinerë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            return False
        except Exception as e:
            print(f"âŒ GLiNER ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def extract_entities(self, text: str) -> List[Dict[str, Any]]:
        """GLiNERë¡œ ê°œì²´ëª… ì¶”ì¶œ"""
        if not self.loaded or not self.model:
            return []
        
        try:
            # GLiNER ì‚¬ìš©ë²•
            entities = self.model.predict_entities(
                text, 
                ["person", "location", "organization"]  # ì˜ì–´ ë¼ë²¨
            )
            
            results = []
            for entity in entities:
                pii_type = {
                    "person": "ì´ë¦„",
                    "location": "ì£¼ì†Œ", 
                    "organization": "íšŒì‚¬"
                }.get(entity['label'], "ê¸°íƒ€")
                
                results.append({
                    "type": pii_type,
                    "value": entity['text'],
                    "start": entity['start'],
                    "end": entity['end'],
                    "confidence": entity['score'],
                    "source": "GLiNER"
                })
            
            return results
            
        except Exception as e:
            print(f"âŒ GLiNER ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []

# ì „ì—­ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤)
_ner_model_instance = None

def get_ner_model() -> WorkingNERModel:
    """NER ëª¨ë¸ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _ner_model_instance
    
    if _ner_model_instance is None:
        _ner_model_instance = WorkingNERModel()
    
    return _ner_model_instance

def load_ner_model() -> bool:
    """NER ëª¨ë¸ ë¡œë“œ"""
    model = get_ner_model()
    success = model.load_model()
    
    # ê¸°ë³¸ ëª¨ë¸ ì‹¤íŒ¨ ì‹œ GLiNER ì‹œë„
    if not success:
        print("ğŸ”„ GLiNER ëª¨ë¸ë¡œ ëŒ€ì•ˆ ì‹œë„...")
        gliner = GLiNERModel()
        return gliner.load_model()
    
    return success

def extract_entities_with_ner(text: str) -> List[Dict[str, Any]]:
    """NER ëª¨ë¸ì„ ì‚¬ìš©í•œ ê°œì²´ëª… ì¶”ì¶œ"""
    model = get_ner_model()
    
    if not model.is_loaded():
        print("âš ï¸ NER ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []
    
    return model.extract_entities(text)

def is_ner_available() -> bool:
    """NER ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    return NER_AVAILABLE

def is_ner_loaded() -> bool:
    """NER ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸"""
    model = get_ner_model()
    return model.is_loaded()

def get_model_info() -> Dict[str, Any]:
    """í˜„ì¬ ë¡œë“œëœ ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
    model = get_ner_model()
    
    base_info = {
        "loaded": model.is_loaded(),
        "model_name": model.model_name if model.is_loaded() else None,
        "device": model.device,
        "available_models": NER_MODELS
    }
    
    if model.is_loaded():
        base_info.update(model.get_performance_stats())
    
    return base_info

# í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ í•¨ìˆ˜ë“¤
def call_qwen_detect_pii(original_prompt: str, model=None, tokenizer=None, device=None) -> Dict[str, Any]:
    """ê¸°ì¡´ í˜¸í™˜ì„ ìœ„í•œ í•¨ìˆ˜ (deprecated)"""
    print("âš ï¸ call_qwen_detect_piiëŠ” deprecatedì…ë‹ˆë‹¤. extract_entities_with_nerë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
    
    entities = extract_entities_with_ner(original_prompt)
    
    return {
        "items": entities,
        "contains_pii": len(entities) > 0
    }

def pick_device_and_dtype():
    """ë””ë°”ì´ìŠ¤ ë° ë°ì´í„° íƒ€ì… ì„ íƒ (í˜¸í™˜ì„±)"""
    model = get_ner_model()
    device = model.device
    
    if device == 0:  # GPU
        return "cuda", torch.float16
    elif device == "mps":  # Apple Silicon
        return "mps", torch.float16
    else:  # CPU
        return "cpu", torch.float32

def load_model():
    """ëª¨ë¸ ë¡œë“œ (í˜¸í™˜ì„±)"""
    return load_ner_model()

# ëª¨ë“ˆ ì´ˆê¸°í™” ì‹œ ì •ë³´ ì¶œë ¥
if __name__ == "__main__":
    print("ğŸ­ ì‹¤ì œ ì‘ë™í•˜ëŠ” í•œêµ­ì–´ NER ëª¨ë¸ ëª¨ë“ˆ")
    print(f"ğŸ“± Transformers ì‚¬ìš© ê°€ëŠ¥: {NER_AVAILABLE}")
    print(f"ğŸ¯ ëª©í‘œ: 100-300ms ì‹¤ì‹œê°„ ì¶”ë¡ ")
    print(f"ğŸ”§ ìˆ˜ì •ì‚¬í•­: íŒŒë¼ë¯¸í„° ì˜¤ë¥˜ í•´ê²°, ì‹¤ì¡´ ëª¨ë¸ë§Œ ì‚¬ìš©")
    print(f"ğŸ¤– ê²€ì¦ëœ ëª¨ë¸ë“¤:")
    
    for i, model in enumerate(NER_MODELS, 1):
        print(f"   {i}. {model}")
    
    if NER_AVAILABLE:
        print("\nğŸ”„ ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        success = load_ner_model()
        
        if success:
            print("\nğŸ§ª ì£¼ì†Œ ì¸ì‹ í…ŒìŠ¤íŠ¸:")
            test_cases = [
                "ì´ì˜í¬ë‹˜ì€ ì„œìš¸ ê°•ë‚¨êµ¬ì— ì‚´ê³  ìˆìŠµë‹ˆë‹¤.",
                "ê¹€ì² ìˆ˜ëŠ” ë¶€ì‚° í•´ìš´ëŒ€êµ¬ ì„¼í…€ì‹œí‹° ê±°ì£¼í•©ë‹ˆë‹¤.",
                "ëŒ€êµ¬ ì¤‘êµ¬ ë™ì„±ë¡œì—ì„œ ë§Œë‚˜ìš”."
            ]
            
            for i, test_text in enumerate(test_cases, 1):
                entities = extract_entities_with_ner(test_text)
                address_found = any(e['type'] == 'ì£¼ì†Œ' for e in entities)
                print(f"   í…ŒìŠ¤íŠ¸ {i}: {'âœ…' if address_found else 'âŒ'} '{test_text}'")
                if entities:
                    for entity in entities:
                        print(f"      - {entity['type']}: {entity['value']} (ì‹ ë¢°ë„: {entity['confidence']:.3f})")
        else:
            print("âŒ ëª¨ë“  ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
            print("ğŸ’¡ ëŒ€ì•ˆ: GLiNER ì„¤ì¹˜ ì‹œë„ - pip install gliner")