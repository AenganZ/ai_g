# pseudonymization/model.py - AenganZ NER ëª¨ë¸ (ëª¨ë“ˆí™” ë²„ì „)
import os
import torch
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor

# NER ëª¨ë¸ ê´€ë ¨ import
try:
    from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
    NER_AVAILABLE = True
except ImportError:
    NER_AVAILABLE = False
    print("âš ï¸ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. pip install transformers torchë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

# AenganZì—ì„œ ì‚¬ìš©í•˜ëŠ” NER ëª¨ë¸ ì„¤ì •
AENGANZ_NER_MODEL = "monologg/koelectra-base-v3-naver-ner"

class AenganZNERModel:
    """AenganZ ë°©ì‹ì˜ NER ëª¨ë¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.model = None
        self.tokenizer = None
        self.pipeline = None
        self.device = self._get_device()
        self.loaded = False
    
    def _get_device(self):
        """ìµœì ì˜ ë””ë°”ì´ìŠ¤ ì„ íƒ"""
        if torch.cuda.is_available():
            return 0  # GPU
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            return "mps"  # Apple Silicon
        else:
            return -1  # CPU
    
    def load_model(self) -> bool:
        """AenganZ ë°©ì‹ì˜ NER ëª¨ë¸ ë¡œë“œ"""
        if not NER_AVAILABLE:
            print("âŒ NER ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤")
            return False
        
        try:
            print(f"ğŸ”„ NER ëª¨ë¸ ë¡œë”© ì¤‘... ({AENGANZ_NER_MODEL})")
            
            # í† í¬ë‚˜ì´ì €ì™€ ëª¨ë¸ ë¡œë“œ
            self.tokenizer = AutoTokenizer.from_pretrained(AENGANZ_NER_MODEL)
            self.model = AutoModelForTokenClassification.from_pretrained(AENGANZ_NER_MODEL)
            
            # íŒŒì´í”„ë¼ì¸ ìƒì„±
            self.pipeline = pipeline(
                "ner", 
                model=self.model, 
                tokenizer=self.tokenizer,
                aggregation_strategy="simple",
                device=self.device
            )
            
            self.loaded = True
            print("âœ… AenganZ NER ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
            print(f"   ğŸ“± ë””ë°”ì´ìŠ¤: {self.device}")
            print(f"   ğŸ¤– ëª¨ë¸: {AENGANZ_NER_MODEL}")
            return True
            
        except Exception as e:
            print(f"âŒ NER ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ í•´ê²° ë°©ë²•:")
            print("   1. ì¸í„°ë„· ì—°ê²° í™•ì¸")
            print("   2. pip install transformers torch")
            print("   3. Hugging Face ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¬ì‹œë„")
            self.loaded = False
            return False
    
    def is_loaded(self) -> bool:
        """ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸"""
        return self.loaded
    
    def extract_entities(self, text: str) -> List[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ì—ì„œ ê°œì²´ëª… ì¶”ì¶œ (AenganZ ë°©ì‹)"""
        if not self.loaded or not self.pipeline:
            return []
        
        try:
            # NER íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            ner_results = self.pipeline(text)
            
            entities = []
            for entity in ner_results:
                entity_type = entity['entity_group']
                entity_text = entity['word']
                confidence = entity['score']
                start = entity['start']
                end = entity['end']
                
                # ì‹ ë¢°ë„ ì„ê³„ê°’ (AenganZ ê¸°ì¤€)
                if confidence > 0.7:
                    pii_type = self._map_ner_label_to_pii_type(entity_type)
                    if pii_type:
                        entities.append({
                            "type": pii_type,
                            "value": entity_text,
                            "start": start,
                            "end": end,
                            "confidence": confidence,
                            "source": "NER"
                        })
            
            return entities
            
        except Exception as e:
            print(f"âŒ NER ê°œì²´ëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def _map_ner_label_to_pii_type(self, label: str) -> Optional[str]:
        """NER ë¼ë²¨ì„ PII íƒ€ì…ìœ¼ë¡œ ë§¤í•‘ (AenganZ ë°©ì‹)"""
        mapping = {
            'PER': 'ì´ë¦„',
            'PERSON': 'ì´ë¦„',
            'LOC': 'ì£¼ì†Œ',
            'LOCATION': 'ì£¼ì†Œ',
            'ORG': 'íšŒì‚¬',
            'ORGANIZATION': 'íšŒì‚¬'
        }
        return mapping.get(label)

# ì „ì—­ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
_ner_model_instance = None

def get_ner_model() -> AenganZNERModel:
    """NER ëª¨ë¸ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _ner_model_instance
    
    if _ner_model_instance is None:
        _ner_model_instance = AenganZNERModel()
    
    return _ner_model_instance

def load_ner_model() -> bool:
    """NER ëª¨ë¸ ë¡œë“œ (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ê°€ëŠ¥)"""
    model = get_ner_model()
    return model.load_model()

def extract_entities_with_ner(text: str) -> List[Dict[str, Any]]:
    """NER ëª¨ë¸ì„ ì‚¬ìš©í•œ ê°œì²´ëª… ì¶”ì¶œ"""
    model = get_ner_model()
    
    if not model.is_loaded():
        print("âš ï¸ NER ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € load_ner_model()ì„ í˜¸ì¶œí•˜ì„¸ìš”.")
        return []
    
    return model.extract_entities(text)

def is_ner_available() -> bool:
    """NER ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    return NER_AVAILABLE

def is_ner_loaded() -> bool:
    """NER ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸"""
    model = get_ner_model()
    return model.is_loaded()

# í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ í•¨ìˆ˜ë“¤
def call_qwen_detect_pii(original_prompt: str, model=None, tokenizer=None, device=None) -> Dict[str, Any]:
    """ê¸°ì¡´ Qwen ë°©ì‹ í˜¸í™˜ì„ ìœ„í•œ í•¨ìˆ˜ (AenganZ NERë¡œ ë³€ê²½)"""
    print("âš ï¸ call_qwen_detect_piiëŠ” deprecatedì…ë‹ˆë‹¤. extract_entities_with_nerë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
    
    # AenganZ NER ëª¨ë¸ ì‚¬ìš©
    entities = extract_entities_with_ner(original_prompt)
    
    return {
        "items": entities,
        "contains_pii": len(entities) > 0
    }

def pick_device_and_dtype():
    """ë””ë°”ì´ìŠ¤ ë° ë°ì´í„° íƒ€ì… ì„ íƒ (í˜¸í™˜ì„±)"""
    model = get_ner_model()
    device = model.device
    
    if device == 0:  # GPU
        return "cuda", torch.bfloat16
    elif device == "mps":  # Apple Silicon
        return "mps", torch.float16
    else:  # CPU
        return "cpu", torch.float32

def load_model():
    """ëª¨ë¸ ë¡œë“œ (í˜¸í™˜ì„±)"""
    return load_ner_model()

# ëª¨ë“ˆ ì´ˆê¸°í™” ì‹œ ì •ë³´ ì¶œë ¥
if __name__ == "__main__":
    print("ğŸ­ AenganZ NER ëª¨ë¸ ëª¨ë“ˆ")
    print(f"ğŸ“± Transformers ì‚¬ìš© ê°€ëŠ¥: {NER_AVAILABLE}")
    print(f"ğŸ¤– ëª¨ë¸: {AENGANZ_NER_MODEL}")
    
    if NER_AVAILABLE:
        model = get_ner_model()
        success = model.load_model()
        if success:
            # í…ŒìŠ¤íŠ¸
            test_text = "ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ê¹€í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤."
            entities = model.extract_entities(test_text)
            print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ê²°ê³¼: {len(entities)}ê°œ ê°œì²´ íƒì§€")
            for entity in entities:
                print(f"   {entity['type']}: {entity['value']} (ì‹ ë¢°ë„: {entity['confidence']:.2f})")
        else:
            print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")