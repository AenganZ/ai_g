# pseudonymization/model.py
"""
NER ëª¨ë¸ ê´€ë¦¬ ëª¨ë“ˆ - ìˆ˜ì •ëœ ë²„ì „
BIO íƒœê·¸ ë¬¸ì œ í•´ê²° ë° ì •í™•í•œ ì—”í‹°í‹° íƒ€ì… ì¶”ì¶œ
"""

import time
from typing import List, Dict, Any, Optional

# NER ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„ íƒì )
try:
    import torch
    from transformers import (
        AutoModelForTokenClassification, 
        AutoTokenizer, 
        pipeline
    )
    NER_AVAILABLE = True
except ImportError:
    NER_AVAILABLE = False
    print("âš ï¸ transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ê²€ì¦ëœ í•œêµ­ì–´ NER ëª¨ë¸ë“¤
NER_MODELS = [
    "monologg/koelectra-base-v3-naver-ner",     # ë„¤ì´ë²„ ë°ì´í„°
    "Leo97/KoELECTRA-small-v3-modu-ner",        # ëª¨ë‘ì˜ ë§ë­‰ì¹˜
    "KPF/KPF-bert-ner",                         # í•œêµ­ì–¸ë¡ ì§„í¥ì¬ë‹¨
]

class WorkingNERModel:
    """ì‹¤ì œ ì‘ë™í•˜ëŠ” ê°œì„ ëœ NER ëª¨ë¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.model = None
        self.tokenizer = None
        self.pipeline = None
        self.device = self._get_device()
        self.loaded = False
        self.model_name = None
        self.id2label = None  # ë¼ë²¨ ë§¤í•‘ ì €ì¥
    
    def _get_device(self):
        """ìµœì ì˜ ë””ë°”ì´ìŠ¤ ì„ íƒ"""
        if torch.cuda.is_available():
            return 0  # GPU
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            return "mps"  # Apple Silicon
        else:
            return -1  # CPU
    
    def is_loaded(self) -> bool:
        """ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸"""
        return self.loaded
    
    def load_model(self) -> bool:
        """NER ëª¨ë¸ ë¡œë“œ - aggregation_strategy ì—†ì´ ì›ì‹œ í† í° ì²˜ë¦¬"""
        if not NER_AVAILABLE:
            print("âŒ NER ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤")
            return False
        
        for model_name in NER_MODELS:
            try:
                print(f"ğŸ”„ NER ëª¨ë¸ ë¡œë”© ì‹œë„: {model_name}")
                
                # í† í¬ë‚˜ì´ì €ì™€ ëª¨ë¸ ë¡œë“œ
                self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                self.model = AutoModelForTokenClassification.from_pretrained(model_name)
                
                # ë¼ë²¨ ë§¤í•‘ ì €ì¥ (ì¤‘ìš”!)
                self.id2label = self.model.config.id2label
                print(f"   ğŸ“‹ ë¼ë²¨ ë§¤í•‘: {list(self.id2label.values())[:10]}...")
                
                # íŒŒì´í”„ë¼ì¸ ìƒì„± - aggregation ì—†ì´ ì›ì‹œ í† í° ë ˆë²¨ ê²°ê³¼
                self.pipeline = pipeline(
                    "ner", 
                    model=self.model, 
                    tokenizer=self.tokenizer,
                    aggregation_strategy=None,  # ì›ì‹œ í† í° ë ˆë²¨ ê²°ê³¼ ë°›ê¸°
                    device=self.device
                )
                
                # í…ŒìŠ¤íŠ¸
                test_text = "ê¹€ì² ìˆ˜ëŠ” ì„œìš¸ ê°•ë‚¨êµ¬ì— ì‚´ê³  ìˆìŠµë‹ˆë‹¤."
                test_result = self._process_raw_ner_output(self.pipeline(test_text), test_text)
                
                self.loaded = True
                self.model_name = model_name
                print(f"âœ… NER ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_name}")
                print(f"   ğŸ§ª í…ŒìŠ¤íŠ¸ ê²°ê³¼: {len(test_result)}ê°œ ì—”í‹°í‹° íƒì§€")
                for entity in test_result:
                    print(f"      - {entity['type']}: {entity['value']}")
                return True
                
            except Exception as e:
                print(f"âŒ {model_name} ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue
        
        print("âŒ ëª¨ë“  NER ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
        return False
    
    def _process_raw_ner_output(self, raw_results: List[Dict], original_text: str) -> List[Dict[str, Any]]:
        """ì›ì‹œ NER ì¶œë ¥ì„ ì²˜ë¦¬í•˜ì—¬ ì—”í‹°í‹° ì¶”ì¶œ (í˜¸í™˜ì„±ìš©)"""
        # aggregation_strategy="simple" ì‚¬ìš© ì‹œ ì´ë¯¸ ì²˜ë¦¬ëœ ê²°ê³¼
        entities = []
        
        for entity in raw_results:
            entity_group = entity.get('entity_group', '')
            word = entity.get('word', '').strip()
            score = entity.get('score', 0.0)
            start = entity.get('start', 0)
            end = entity.get('end', 0)
            
            # í† í¬ë‚˜ì´ì € ì•„í‹°íŒ©íŠ¸ ì œê±°
            word = word.replace('##', '').replace('â–', ' ').strip()
            
            # entity_group ë§¤í•‘
            pii_type = self._map_entity_type(entity_group)
            
            # í•„í„°ë§
            threshold = 0.5 if pii_type == 'ì£¼ì†Œ' else 0.6
            
            if score > threshold and len(word) >= 2 and pii_type != 'ê¸°íƒ€':
                entities.append({
                    'type': pii_type,
                    'value': word,
                    'start': start,
                    'end': end,
                    'score': score,
                    'source': 'NER'
                })
        
        return entities
    
    def extract_entities(self, text: str) -> List[Dict[str, Any]]:
        """ê°œì²´ëª… ì¶”ì¶œ - aggregation_strategy ì‚¬ìš©"""
        if not self.loaded or not self.pipeline:
            return []
        
        try:
            # NER ì‹¤í–‰ (aggregation_strategy="simple" ì‚¬ìš©)
            ner_results = self.pipeline(text)
            
            entities = []
            for entity in ner_results:
                entity_group = entity.get('entity_group', '')
                word = entity.get('word', '')
                score = entity.get('score', 0.0)
                start = entity.get('start', 0)
                end = entity.get('end', 0)
                
                # í† í¬ë‚˜ì´ì € ì•„í‹°íŒ©íŠ¸ ì œê±°
                word = word.replace('##', '').replace('â–', ' ').strip()
                
                # entity_group ë§¤í•‘
                pii_type = self._map_entity_type(entity_group)
                
                # í•„í„°ë§
                threshold = 0.5 if pii_type == 'ì£¼ì†Œ' else 0.6
                
                if score > threshold and len(word) >= 2 and pii_type != 'ê¸°íƒ€':
                    entities.append({
                        'type': pii_type,
                        'value': word,
                        'start': start,
                        'end': end,
                        'score': score,
                        'source': 'NER'
                    })
                    print(f"   âœ… NER íƒì§€: {pii_type} = '{word}' (ì‹ ë¢°ë„: {score:.3f})")
            
            print(f"ğŸ¤– NER ({self.model_name.split('/')[-1]}) íƒì§€: {len(entities)}ê°œ")
            return entities
            
        except Exception as e:
            print(f"âŒ NER ê°œì²´ëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _map_entity_type(self, entity_type: str) -> str:
        """ì—”í‹°í‹° íƒ€ì…ì„ ìš°ë¦¬ ì‹œìŠ¤í…œ íƒ€ì…ìœ¼ë¡œ ë§¤í•‘"""
        entity_type = entity_type.upper()
        
        mapping = {
            # í‘œì¤€ ì—”í‹°í‹° íƒ€ì…
            'PER': 'ì´ë¦„',
            'PS': 'ì´ë¦„',       # Person (KLUE)
            'PERSON': 'ì´ë¦„',
            
            'LOC': 'ì£¼ì†Œ',
            'LC': 'ì£¼ì†Œ',       # Location (KLUE)
            'LOCATION': 'ì£¼ì†Œ',
            
            'ORG': 'íšŒì‚¬',
            'OG': 'íšŒì‚¬',       # Organization (KLUE)
            'ORGANIZATION': 'íšŒì‚¬',
            
            'DT': 'ë‚ ì§œ',       # Date
            'TI': 'ì‹œê°„',       # Time
            'QT': 'ìˆ˜ëŸ‰',       # Quantity
        }
        
        return mapping.get(entity_type, 'ê¸°íƒ€')

# ì „ì—­ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
_ner_model_instance = None

def get_ner_model() -> WorkingNERModel:
    """NER ëª¨ë¸ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _ner_model_instance
    
    if _ner_model_instance is None:
        _ner_model_instance = WorkingNERModel()
    
    return _ner_model_instance

def load_ner_model() -> bool:
    """NER ëª¨ë¸ ë¡œë“œ"""
    model = get_ner_model()
    return model.load_model()

def extract_entities_with_ner(text: str) -> List[Dict[str, Any]]:
    """NER ëª¨ë¸ì„ ì‚¬ìš©í•œ ê°œì²´ëª… ì¶”ì¶œ"""
    model = get_ner_model()
    
    if not model.is_loaded():
        print("âš ï¸ NER ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []
    
    return model.extract_entities(text)

def is_ner_available() -> bool:
    """NER ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    return NER_AVAILABLE

def is_ner_loaded() -> bool:
    """NER ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸"""
    model = get_ner_model()
    return model.is_loaded()

# í˜¸í™˜ì„± í•¨ìˆ˜ë“¤
def call_qwen_detect_pii(original_prompt: str, model=None, tokenizer=None, device=None) -> Dict[str, Any]:
    """ê¸°ì¡´ í˜¸í™˜ì„ ìœ„í•œ í•¨ìˆ˜"""
    entities = extract_entities_with_ner(original_prompt)
    return {
        "items": entities,
        "contains_pii": len(entities) > 0
    }

def pick_device_and_dtype():
    """ë””ë°”ì´ìŠ¤ ë° ë°ì´í„° íƒ€ì… ì„ íƒ"""
    model = get_ner_model()
    device = model.device
    
    if device == 0:  # GPU
        return "cuda", torch.float16
    elif device == "mps":  # Apple Silicon
        return "mps", torch.float16
    else:  # CPU
        return "cpu", torch.float32

def load_model():
    """ëª¨ë¸ ë¡œë“œ (í˜¸í™˜ì„±)"""
    return load_ner_model()

# ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    print("ğŸ­ ê°œì„ ëœ í•œêµ­ì–´ NER ëª¨ë¸ ëª¨ë“ˆ")
    print("ğŸ”§ BIO íƒœê·¸ ë¬¸ì œ í•´ê²°")
    
    if NER_AVAILABLE:
        print("\nğŸ”„ ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸...")
        success = load_ner_model()
        
        if success:
            print("\nğŸ§ª í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰:")
            test_cases = [
                "ê¹€ì² ìˆ˜ ê³ ê°ë‹˜, ë¶€ì‚° í•´ìš´ëŒ€êµ¬ ì˜ˆì•½ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤. ë¬¸ì˜ì‚¬í•­ì€ 010-9876-5432ë¡œ ì—°ë½ ì£¼ì„¸ìš”.",
                "ì´ì˜í¬ë‹˜ì€ ì„œìš¸ ê°•ë‚¨êµ¬ì— ì‚´ê³  ìˆìŠµë‹ˆë‹¤.",
                "ë°•ë¯¼ìˆ˜ëŠ” ì‚¼ì„±ì „ìì—ì„œ ì¼í•˜ê³  ìˆìŠµë‹ˆë‹¤."
            ]
            
            for test_text in test_cases:
                print(f"\ní…ŒìŠ¤íŠ¸: '{test_text}'")
                entities = extract_entities_with_ner(test_text)
                
                if entities:
                    for entity in entities:
                        print(f"  - {entity['type']}: {entity['value']} (ì‹ ë¢°ë„: {entity['score']:.3f})")
                else:
                    print("  íƒì§€ëœ ì—”í‹°í‹° ì—†ìŒ")